<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Oakestra</title>
        <link>https://oakestra.io/</link>
        <description>Recent content on Oakestra</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Wed, 10 Aug 2022 11:28:03 +0200</lastBuildDate><atom:link href="https://oakestra.io/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Contacts</title>
        <link>https://oakestra.io/about/contacts/</link>
        <pubDate>Wed, 10 Aug 2022 11:28:03 +0200</pubDate>
        
        <guid>https://oakestra.io/about/contacts/</guid>
        <description>&lt;h2 id=&#34;our-discussion-group&#34;&gt;Our discussion group&lt;/h2&gt;
&lt;p&gt;Join our github discussion group &lt;a class=&#34;link&#34; href=&#34;https://github.com/oakestra/oakestra/discussions&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;HERE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Feel free to post questions and ideas or ask about any problem you have.&lt;/p&gt;
&lt;p&gt;In our team section, you can also find a list of people you can contact directly by email, socials, and, why not, carrier pigeons as well.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Team</title>
        <link>https://oakestra.io/about/team/</link>
        <pubDate>Wed, 10 Aug 2022 11:27:56 +0200</pubDate>
        
        <guid>https://oakestra.io/about/team/</guid>
        <description>&lt;ul&gt;
&lt;li&gt;Giovanni Bartolomeo
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;mailto:giovanni.bartolomeo@tum.de&#34; &gt;giovanni.bartolomeo@tum.de&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mehdi Yosofie&lt;/li&gt;
&lt;li&gt;Oliver Haluszczynsci&lt;/li&gt;
&lt;li&gt;Simon Bäurle&lt;/li&gt;
&lt;li&gt;Maximilian Eder&lt;/li&gt;
&lt;li&gt;Patrick Sabanic&lt;/li&gt;
&lt;li&gt;Sonia Klärmann&lt;/li&gt;
&lt;li&gt;Ralf Baun&lt;/li&gt;
&lt;li&gt;Daniel Mair&lt;/li&gt;
&lt;li&gt;Maria Vienalas&lt;/li&gt;
&lt;li&gt;Dr. Nitinder Mohan
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;mailto:mohan@in.tum.de&#34; &gt;mohan@in.tum.de&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Prof. Jörg Ott&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Contributor Covenant Code of Conduct</title>
        <link>https://oakestra.io/docs/contribute/coc/</link>
        <pubDate>Tue, 09 Aug 2022 15:56:27 +0200</pubDate>
        
        <guid>https://oakestra.io/docs/contribute/coc/</guid>
        <description>&lt;h1 id=&#34;contributor-covenant-code-of-conduct&#34;&gt;Contributor Covenant Code of Conduct&lt;/h1&gt;
&lt;h2 id=&#34;our-pledge&#34;&gt;Our Pledge&lt;/h2&gt;
&lt;p&gt;In the interest of fostering an open and welcoming environment, we as
contributors and maintainers pledge to make participation in our project and
our community a harassment-free experience for everyone, regardless of age, body
size, disability, ethnicity, sex characteristics, gender identity and expression,
level of experience, education, socio-economic status, nationality, personal
appearance, race, religion, or sexual identity and orientation.&lt;/p&gt;
&lt;h2 id=&#34;our-standards&#34;&gt;Our Standards&lt;/h2&gt;
&lt;p&gt;Examples of behavior that contributes to creating a positive environment
include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using welcoming and inclusive language&lt;/li&gt;
&lt;li&gt;Being respectful of differing viewpoints and experiences&lt;/li&gt;
&lt;li&gt;Gracefully accepting constructive criticism&lt;/li&gt;
&lt;li&gt;Focusing on what is best for the community&lt;/li&gt;
&lt;li&gt;Showing empathy towards other community members&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples of unacceptable behavior by participants include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The use of sexualized language or imagery and unwelcome sexual attention or
advances&lt;/li&gt;
&lt;li&gt;Trolling, insulting/derogatory comments, and personal or political attacks&lt;/li&gt;
&lt;li&gt;Public or private harassment&lt;/li&gt;
&lt;li&gt;Publishing others&amp;rsquo; private information, such as a physical or electronic
address, without explicit permission&lt;/li&gt;
&lt;li&gt;Other conduct which could reasonably be considered inappropriate in a
professional setting&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;our-responsibilities&#34;&gt;Our Responsibilities&lt;/h2&gt;
&lt;p&gt;Project maintainers are responsible for clarifying the standards of acceptable
behavior and are expected to take appropriate and fair corrective action in
response to any instances of unacceptable behavior.&lt;/p&gt;
&lt;p&gt;Project maintainers have the right and responsibility to remove, edit, or
reject comments, commits, code, wiki edits, issues, and other contributions
that are not aligned to this Code of Conduct, or to ban temporarily or
permanently any contributor for other behaviors that they deem inappropriate,
threatening, offensive, or harmful.&lt;/p&gt;
&lt;h2 id=&#34;scope&#34;&gt;Scope&lt;/h2&gt;
&lt;p&gt;This Code of Conduct applies within all project spaces, and it also applies when
an individual is representing the project or its community in public spaces.
Examples of representing a project or community include using an official
project e-mail address, posting via an official social media account, or acting
as an appointed representative at an online or offline event. Representation of
a project may be further defined and clarified by project maintainers.&lt;/p&gt;
&lt;h2 id=&#34;enforcement&#34;&gt;Enforcement&lt;/h2&gt;
&lt;p&gt;Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported by contacting the project team at [INSERT EMAIL ADDRESS]. All
complaints will be reviewed and investigated and will result in a response that
is deemed necessary and appropriate to the circumstances. The project team is
obligated to maintain confidentiality with regard to the reporter of an incident.
Further details of specific enforcement policies may be posted separately.&lt;/p&gt;
&lt;p&gt;Project maintainers who do not follow or enforce the Code of Conduct in good
faith may face temporary or permanent repercussions as determined by other
members of the project&amp;rsquo;s leadership.&lt;/p&gt;
&lt;h2 id=&#34;attribution&#34;&gt;Attribution&lt;/h2&gt;
&lt;p&gt;This Code of Conduct is adapted from the &lt;a class=&#34;link&#34; href=&#34;https://www.contributor-covenant.org&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Contributor Covenant&lt;/a&gt;, version 1.4,
available at &lt;a class=&#34;link&#34; href=&#34;https://www.contributor-covenant.org/version/1/4/code-of-conduct.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.contributor-covenant.org/version/1/4/code-of-conduct.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For answers to common questions about this code of conduct, see
&lt;a class=&#34;link&#34; href=&#34;https://www.contributor-covenant.org/faq&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.contributor-covenant.org/faq&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Deploy your first application</title>
        <link>https://oakestra.io/docs/operations/application-deployment/</link>
        <pubDate>Tue, 09 Aug 2022 15:56:27 +0200</pubDate>
        
        <guid>https://oakestra.io/docs/operations/application-deployment/</guid>
        <description>&lt;h1 id=&#34;documentation-available-soon-stay-tuned&#34;&gt;Documentation available soon. Stay tuned.&lt;/h1&gt;
</description>
        </item>
        <item>
        <title>High level architecture</title>
        <link>https://oakestra.io/docs/oakestra/architecture/</link>
        <pubDate>Tue, 09 Aug 2022 15:56:27 +0200</pubDate>
        
        <guid>https://oakestra.io/docs/oakestra/architecture/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;https://oakestra.io/oakestra/wiki-banner-help.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;table-of-content&#34;&gt;Table of content&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#root-orchestrator&#34; &gt;Root Orchestrator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#cluster-orchestrator&#34; &gt;Cluster Orchestrator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#worker-node&#34; &gt;Worker Node&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;oakestra-detailed-architecture&#34;&gt;Oakestra Detailed Architecture&lt;/h1&gt;
&lt;p&gt;As shown in our &lt;a class=&#34;link&#34; href=&#34;get-started.md&#34; &gt;Get Started&lt;/a&gt; guide, Oakestra uses 3-4 building blocks to operate.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Root Orchestrator&lt;/li&gt;
&lt;li&gt;Cluster Orchestrator&lt;/li&gt;
&lt;li&gt;Node Engine&lt;/li&gt;
&lt;li&gt;NetManager (optional)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This section of the wiki is intended for people willing to contribute to the project and it is meant to describe some internal architectural details.&lt;/p&gt;
&lt;h2 id=&#34;root-orchestrator&#34;&gt;Root Orchestrator&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/oakestra/RootArch.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;The Root Orchestrator is a centralized control plane that is aware of the participating clusters.&lt;/p&gt;
&lt;p&gt;This picture describes the containers that compose the Root Orchestrator. As you may have seen we use docker-compose to bring up the orchestrators. This is because each block of this picture is &lt;em&gt;currently&lt;/em&gt; a separated container.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The System Manager is the point of contact for users, developers, or operators to use the system as an application deployment platform. It exposes APIs to receive deployment commands from users (application management) and APIs to handle slave Cluster Orchestrators. Cluster Orchestrators send their information
regularly, and the System Manager is aware of those clusters.&lt;/li&gt;
&lt;li&gt;The scheduler calculates a placement for a given application within the available clusters.&lt;/li&gt;
&lt;li&gt;Mongo is the interface we use to access the database. We store aggregated information about the participating clusters. We differentiate between static metadata and dynamic data. The former covers the IP address, port number, name, and location of each cluster. The latter can be data that is
changing regularly, such as the number of worker nodes per cluster, total amount of CPU cores and memory size, total amount of disk space, GPU capabilities, etc.&lt;/li&gt;
&lt;li&gt;The Root Network Components are detailed in the Oakestra-Net Wiki.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;system-manager-apis&#34;&gt;System Manager APIs&lt;/h3&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;h3 id=&#34;jobs-db-structure&#34;&gt;Jobs DB Structure&lt;/h3&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;h3 id=&#34;clusters-db-structure&#34;&gt;Clusters DB Structure&lt;/h3&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;h3 id=&#34;scheduler-algorithms&#34;&gt;Scheduler Algorithms&lt;/h3&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;h3 id=&#34;consideration-regarding-failure-and-scalability&#34;&gt;Consideration regarding failure and scalability:&lt;/h3&gt;
&lt;p&gt;The main problem of a centralized control plane is that it can act as a single point of failure. By design without a Root Orchestrator, the clusters are able to satisfy the SLA for the deployed applications internally, the only affected functionalities are the deployment of new services and the intra-cluster migrations. To avoid failure and increase resiliency an idea is to make the component able to scale by introducing a load balancer in front of the replicated components. However, this feature is not implemented yet.&lt;/p&gt;
&lt;h2 id=&#34;cluster-orchestrator&#34;&gt;Cluster Orchestrator&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/oakestra/ClusterArch.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;h3 id=&#34;cluster-manager-apis&#34;&gt;Cluster Manager APIs&lt;/h3&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;h3 id=&#34;mqtt-topics&#34;&gt;MQTT Topics&lt;/h3&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;h3 id=&#34;jobs-db-structure-1&#34;&gt;Jobs DB structure&lt;/h3&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;h3 id=&#34;nodes-db-structure&#34;&gt;Nodes DB structure&lt;/h3&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;h3 id=&#34;schedulers-algorithms&#34;&gt;Schedulers Algorithms&lt;/h3&gt;
&lt;p&gt;TODO&lt;/p&gt;
&lt;h2 id=&#34;worker-node&#34;&gt;Worker Node&lt;/h2&gt;
&lt;p&gt;TODO&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Oakestra mesh network</title>
        <link>https://oakestra.io/docs/networking/oakestra-mesh/</link>
        <pubDate>Tue, 09 Aug 2022 15:56:27 +0200</pubDate>
        
        <guid>https://oakestra.io/docs/networking/oakestra-mesh/</guid>
        <description>&lt;p&gt;#Docs coming soon, stay tuned&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Orchestration</title>
        <link>https://oakestra.io/docs/oakestra/orchestrators/</link>
        <pubDate>Tue, 09 Aug 2022 15:56:27 +0200</pubDate>
        
        <guid>https://oakestra.io/docs/oakestra/orchestrators/</guid>
        <description>&lt;p&gt;#APIs&lt;/p&gt;
&lt;p&gt;Root Orchestrator APIs &lt;a class=&#34;link&#34; href=&#34;https://app.swaggerhub.com/apis-docs/giobarty/oakestra-root_api/v1#/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;OpenApi Spec&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Task Scheduling</title>
        <link>https://oakestra.io/docs/oakestra/scheduling/</link>
        <pubDate>Tue, 09 Aug 2022 15:56:27 +0200</pubDate>
        
        <guid>https://oakestra.io/docs/oakestra/scheduling/</guid>
        <description>&lt;h2 id=&#34;how-does-the-scheduling-work-in-oakestra&#34;&gt;How does the scheduling work in Oakestra?&lt;/h2&gt;
&lt;p&gt;Oakestra&amp;rsquo;s architecture is composed of two tiers. Resources are divided into clusters. A cluster is seen as the aggregation of all its resources. A job is first scheduled to a cluster, and then the cluster scheduler decides the target worker.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/oakestra/cluster-worker-selection.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;scheduling algo&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;The scheduling component is as simple as a Celery worker. The scheduler receives a job description and gives back an allocation target. We differentiate between the Root scheduler and Cluster scheduler. The Root scheduler finds a suitable cluster (step 1), and the Cluster scheduler finds a suitable worker node (step 2).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/oakestra/scheduling-celery-worker.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;scheduling algo&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;This scheduling algorithm does not ensure an absolute optimal deployment but consistently reduces the search space.&lt;/p&gt;
&lt;h2 id=&#34;scheduling-algorithm&#34;&gt;Scheduling Algorithm&lt;/h2&gt;
&lt;p&gt;At each layer, the scheduling decision consists of the creation of a &lt;code&gt;candidate_list&lt;/code&gt; of clusters (or workers), the exclusion of unsuitable candidates, and then the selection of the &amp;ldquo;best&amp;rdquo; candidate accordingly to a scheduling algorithm.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/oakestra/scheduling-algo.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;scheduling algo&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;The scheduling algorithms are implemented in the &lt;code&gt;calculation.py&lt;/code&gt; component of each respective scheduler.&lt;/p&gt;
&lt;p&gt;The current released version only implements a &lt;strong&gt;best fit&lt;/strong&gt; and &lt;strong&gt;first fit&lt;/strong&gt; calculation strategies. However, on its way to the release, we have our new LDP algorithm (check it out on our &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/2207.01577.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;whitepaper&lt;/a&gt;).&lt;/p&gt;
&lt;h2 id=&#34;job-constraints&#34;&gt;Job Constraints&lt;/h2&gt;
&lt;p&gt;The Job deployment descriptor allows a developer to specify constraints of 4 types: node &lt;strong&gt;resources&lt;/strong&gt;, &lt;strong&gt;network&lt;/strong&gt; capabilities, &lt;strong&gt;geographical&lt;/strong&gt; positioning, and &lt;strong&gt;direct&lt;/strong&gt; mapping.&lt;/p&gt;
&lt;h3 id=&#34;resources&#34;&gt;Resources&lt;/h3&gt;
&lt;p&gt;The job resource requirements cause the immediate exclusion of a candidate from the candidate list. These resources represent the bare minimum required by the job to operate properly. Here there is a table of the supported resources and the state of development:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Resource type&lt;/th&gt;
&lt;th&gt;Status&lt;/th&gt;
&lt;th&gt;Comments&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Virtualization&lt;/td&gt;
&lt;td&gt;🟢&lt;/td&gt;
&lt;td&gt;Fully functional containers support. Unikernel support is under development.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU&lt;/td&gt;
&lt;td&gt;🟢&lt;/td&gt;
&lt;td&gt;Only number of CPU cores&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Memory&lt;/td&gt;
&lt;td&gt;🟢&lt;/td&gt;
&lt;td&gt;Memory requirements in MB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Storage&lt;/td&gt;
&lt;td&gt;🟠&lt;/td&gt;
&lt;td&gt;It is possible to specify it, but it is not &lt;strong&gt;yet&lt;/strong&gt; taken into account by the scheduler&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GPU&lt;/td&gt;
&lt;td&gt;🟠&lt;/td&gt;
&lt;td&gt;Possibility of specifying the GPU cores. But not yet the available GPU drivers. Right now, the support is only for CUDA.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TPU&lt;/td&gt;
&lt;td&gt;🔴&lt;/td&gt;
&lt;td&gt;Not yet under development&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Architecture&lt;/td&gt;
&lt;td&gt;🔴&lt;/td&gt;
&lt;td&gt;Not yet possible to filter out the architecture. With containers, it is possible to use the multi-platform build. This flag is coming out together with the Unikernel support.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;network--geo-constraints&#34;&gt;Network &amp;amp; Geo constraints&lt;/h3&gt;
&lt;p&gt;The networking requirements selection and geographic constraints support are coming out in our next release &lt;strong&gt;v0.5&lt;/strong&gt; and are part of the LDP algorithm update. Stay tuned.&lt;/p&gt;
&lt;h3 id=&#34;direct-mapping-positioning&#34;&gt;Direct mapping positioning&lt;/h3&gt;
&lt;p&gt;It is possible to specify a &lt;strong&gt;direct mapping&lt;/strong&gt; constraint. Therefore, in the deployment description, a developer can specify a list of target clusters and nodes. The scheduling algorithm operates only on the active clusters (or nodes) among the given list.&lt;/p&gt;
&lt;p&gt;This direct mapping approach is currently based on &lt;code&gt;cluster names&lt;/code&gt; and &lt;code&gt;worker hostnames&lt;/code&gt;. We are anyway considering adding a label-based positioning where it is possible to tag resources with custom-defined labels. Stay tuned for more.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Welcome to Oakestra</title>
        <link>https://oakestra.io/p/welcome/</link>
        <pubDate>Tue, 09 Aug 2022 15:56:27 +0200</pubDate>
        
        <guid>https://oakestra.io/p/welcome/</guid>
        <description>&lt;img src="https://oakestra.io/cover.png" alt="Featured image of post Welcome to Oakestra" /&gt;&lt;p&gt;Oakestra is a hierarchical, lightweight, flexible, and scalable orchestration framework for edge computing.&lt;/p&gt;
&lt;p&gt;Through its novel federated cluster management, delegated task scheduling, and semantic overlay networking, Oakestra can flexibly consolidate multiple infrastructure providers and support applications over dynamic variations at the edge.&lt;/p&gt;
&lt;p&gt;Our comprehensive evaluation against the stateof-the-art demonstrates the significant benefits of Oakestra as it achieves approximately 10× resource usage reduction and 10% application performance improvement.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Get Started with Oakestra</title>
        <link>https://oakestra.io/docs/getstarted/get-started/</link>
        <pubDate>Mon, 08 Aug 2022 15:56:27 +0200</pubDate>
        
        <guid>https://oakestra.io/docs/getstarted/get-started/</guid>
        <description>&lt;p&gt;&lt;img src=&#34;https://oakestra.io/wiki-banner-help.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;get-started-with-oakestra&#34;&gt;Get Started with Oakestra&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Table of content:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#high-level-architecture&#34; &gt;High-level archtecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#create-your-first-oakestra-cluster&#34; &gt;Create your first Oakestra cluster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;#deploy-your-first-applications&#34; &gt;Deploy your first applications&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;high-level-architecture&#34;&gt;High-level architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/getstarted/highLevelArch.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;High level architecture picture&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;Oakestra lets you deploy your workload on devices of any size. From a small RasperryPi to a cloud instance far away on GCP or AWS. The tree structure enables you to create multiple clusters of resources.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;strong&gt;Root Orchestrator&lt;/strong&gt; manages different clusters of resources. The root only sees aggregated cluster resources.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;Cluster orchestrator&lt;/strong&gt; manages your worker nodes. This component collects the real-time resources and schedules your workloads to the perfect matching device.&lt;/li&gt;
&lt;li&gt;A &lt;strong&gt;Worker&lt;/strong&gt; is any device where a component called NodeEngine is installed. Each node can support multiple execution environments such as Containers (containerd runtime), MicroVM (containerd runtime), and Unikernels (mirageOS).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disclaimer, currently, only containers are supported. Help is still needed for Unikernels and MicroVMs.&lt;/p&gt;
&lt;h2 id=&#34;create-your-first-oakestra-cluster&#34;&gt;Create your first Oakestra cluster&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s start simple with a single node deployment, where all the components are in the same device. Then, we will separate the components and use multiple devices until we&amp;rsquo;re able to create multiple clusters.&lt;/p&gt;
&lt;h3 id=&#34;requirements&#34;&gt;Requirements:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Linux (Workers only)&lt;/li&gt;
&lt;li&gt;Docker + Docker compose (Orchestrators only)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;1-doc-1-device-one-cluster&#34;&gt;1-DOC (1 Device, One Cluster)&lt;/h3&gt;
&lt;p&gt;In this example, we will use a single device to deploy all the components. This is not recommended for production environments, but it is pretty cool for home environments and development.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/getstarted/SingleNodeExample.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Deployment example with a single device&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0)&lt;/strong&gt; First, let&amp;rsquo;s export the required environment variables&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;## Choose a unique name for your cluster
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;export CLUSTER_NAME=My_Awesome_Cluster
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;## Come up with a name for the current location
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;export CLUSTER_LOCATION=My_Awesome_Apartment
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;1)&lt;/strong&gt; now clone the repository and move into it using:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/edgeIO/edgeio.git &amp;amp;&amp;amp; cd edgeio
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;2)&lt;/strong&gt; Run a local 1-DOC cluster&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo -E docker-compose -f run-a-cluster/1-DOC-&amp;lt;arch&amp;gt;.yml up -d
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;( please replace &amp;lt; arch &amp;gt; with your device architecture: &lt;strong&gt;arm&lt;/strong&gt; or &lt;strong&gt;amd64&lt;/strong&gt; )&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3)&lt;/strong&gt; download, untar and install the node engine package&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget -c https://github.com/oakestra/oakestra/releases/download/NodeEngine-v0.02/NodeEngine.tar.gz &amp;amp;&amp;amp; tar -xzf NodeEngine.tar.gz &amp;amp;&amp;amp; cd NodeEngine/build &amp;amp;&amp;amp; chmod +x install.sh &amp;amp;&amp;amp; ./install.sh &amp;lt;arch&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;( please replace &amp;lt; arch &amp;gt; with your device architecture: &lt;strong&gt;arm-7&lt;/strong&gt; or &lt;strong&gt;amd64&lt;/strong&gt; )&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4)&lt;/strong&gt; (optional) download and unzip and install the network manager; this enables an overlay network across your services&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget -c https://github.com/oakestra/oakestra-net/releases/download/v0.04-experimental/NetManager.tar.gz &amp;amp;&amp;amp; tar -xzf NetManager.tar.gz &amp;amp;&amp;amp; cd NetManager &amp;amp;&amp;amp; chmod +x install.sh &amp;amp;&amp;amp; ./install.sh &amp;lt;arch&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;( please replace &amp;lt; arch &amp;gt; with your device architecture: &lt;strong&gt;arm-7&lt;/strong&gt; or &lt;strong&gt;amd64&lt;/strong&gt; )&lt;/p&gt;
&lt;p&gt;4.1) Edit &lt;code&gt;/etc/netmanager/netcfg.json&lt;/code&gt; as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;NodePublicAddress&amp;#34;: &amp;#34;&amp;lt;IP ADDRESS OF THIS DEVICE&amp;gt;&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;NodePublicPort&amp;#34;: &amp;#34;&amp;lt;PORT REACHABLE FROM OUTSIDE, use 50103 as default&amp;gt;&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;ClusterUrl&amp;#34;: &amp;#34;localhost&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;ClusterMqttPort&amp;#34;: &amp;#34;10003&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;4.2) start the NetManager on port 6000&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo NetManager -p 6000 &amp;amp;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;5)&lt;/strong&gt; start the NodeEngine. Please only use the &lt;code&gt;-n 6000&lt;/code&gt; parameter if you started the network component in step 4. This parameter, in fact, is used to specify the internal port of the network component, if any.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo NodeEngine -n 6000 -p 10100
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;( you can use &lt;code&gt;NodeEngine -h&lt;/code&gt; for further details )&lt;/p&gt;
&lt;h3 id=&#34;m-doc-m-devices-one-cluster&#34;&gt;M-DOC (M Devices, One Cluster)&lt;/h3&gt;
&lt;p&gt;The M-DOC deployment enables you to deploy One cluster with multiple worker nodes. The main difference between this deployment and 1-DOC is that the worker nodes might be external here, and there can be multiple of them.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/getstarted/1ClusterExample.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;The deployment of this kind of cluster is similar to 1-DOC. We first need to start the root and cluster orchestrator. Afterward, we can attach the worker nodes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1)&lt;/strong&gt; On the node you wish to use as a cluster and root orchestrator, execute steps &lt;strong&gt;1-DOC.1&lt;/strong&gt; and &lt;strong&gt;1-DOC.2&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2)&lt;/strong&gt; Now, we need to prepare all the worker nodes. On each worker node, execute the following:&lt;/p&gt;
&lt;p&gt;2.1) Downlaod and unpack both the NodeEngine and the NetManager:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget -c https://github.com/oakestra/oakestra/releases/download/NodeEngine-v0.02/NodeEngine.tar.gz &amp;amp;&amp;amp; tar -xzf NodeEngine.tar.gz &amp;amp;&amp;amp; cd NodeEngine/build &amp;amp;&amp;amp; chmod +x install.sh &amp;amp;&amp;amp; ./install.sh &amp;lt;arch&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;wget -c https://github.com/oakestra/oakestra-net/releases/download/v0.04-experimental/NetManager.tar.gz &amp;amp;&amp;amp; tar -xzf NetManager.tar.gz &amp;amp;&amp;amp; cd NetManager &amp;amp;&amp;amp; chmod +x install.sh &amp;amp;&amp;amp; ./install.sh &amp;lt;arch&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;2.2) Edit &lt;code&gt;/etc/netmanager/netcfg.json&lt;/code&gt; accordingly:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;NodePublicAddress&amp;#34;: &amp;#34;&amp;lt;IP ADDRESS OF THIS DEVICE&amp;gt;&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;NodePublicPort&amp;#34;: &amp;#34;&amp;lt;PORT REACHABLE FROM OUTSIDE, use 50103 as default&amp;gt;&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;ClusterUrl&amp;#34;: &amp;#34;&amp;lt;IP ADDRESS OF THE CLSUTER ORCHESTRATOR&amp;gt;&amp;#34;,
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &amp;#34;ClusterMqttPort&amp;#34;: &amp;#34;10003&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;2.3) Run the NetManager and the NodeEngine components:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo NetManager -p 6000 &amp;amp;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo NodeEngine -n 6000 -p 10100 -a &amp;lt;IP ADDRESS OF THE CLSUTER ORCHESTRATOR&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;mdnc-m-devices-n-clusters&#34;&gt;MDNC (M Devices, N Clusters)&lt;/h3&gt;
&lt;p&gt;This represents the most versatile deployment. You can split your resources into multiple clusters within different locations and with different resources. In this deployment, we need to deploy the Root and the Cluster orchestrator on different nodes. Each independent clsuter orchestrator represents a cluster of resources. The worker nodes attached to each cluster are aggregated and seen as a unique big resource from the point of view of the Root. This deployment isolates the resources from the root perspective and delegates the responsibility to the cluster orchestrator.
&lt;img src=&#34;https://oakestra.io/getstarted/2ClusterExample.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1)&lt;/strong&gt; In this first step, we need to deploy the RootOrchestrator component on a Node. To do this, you need to clone the repository on the desired node, move to the root orchestrator folder, and execute the startup command.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/edgeIO/edgeio.git &amp;amp;&amp;amp; cd edgeio
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo -E docker-compose -f root_orchestrator/docker-compose-&amp;lt;arch&amp;gt;.yml up
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;( please replace &amp;lt; arch &amp;gt; with your device architecture: &lt;strong&gt;arm&lt;/strong&gt; or &lt;strong&gt;amd64&lt;/strong&gt; )&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2)&lt;/strong&gt; For each node that needs to host a cluster orchestrator, you need to:
2.1) Export the ENV variables needed to connect to the cluster orchestrator:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;export SYSTEM_MANAGER_URL=&amp;lt;IP ADDRESS OF THE NODE HOSTING THE ROOT ORCHESTRATOR&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;export CLUSTER_NAME=&amp;lt;choose a name for your cluster&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;export CLUSTER_LOCATION=&amp;lt;choose a name for the cluster&amp;#39;s location&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;2.2) Clone the repo and run the cluster orchestrator:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/edgeIO/edgeio.git &amp;amp;&amp;amp; cd edgeio
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo -E docker-compose -f cluster_orchestrator/docker-compose-&amp;lt;arch&amp;gt;.yml up
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;( please replace &amp;lt; arch &amp;gt; with your device architecture: &lt;strong&gt;arm&lt;/strong&gt; or &lt;strong&gt;amd64&lt;/strong&gt; )&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3)&lt;/strong&gt; Start and configure each worker as described in M-DOC.2&lt;/p&gt;
&lt;h3 id=&#34;hybrids&#34;&gt;Hybrids&lt;/h3&gt;
&lt;p&gt;You should have got the gist now, but if you want, you can build the infrastructure by composing the components like LEGO blocks.
Do you want to give your Cluster Orchestrator computational capabilities for the deployment? Deploy there the NodeEngine+Netmanager components, and you&amp;rsquo;re done. You don&amp;rsquo;t want to use a separate node for the Root Orchestrator? Simply deploy it all together with a cluster orchestrator.&lt;/p&gt;
&lt;h2 id=&#34;deploy-your-first-application&#34;&gt;Deploy your first application&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s try deploying an Nginx server and a client. Then we&amp;rsquo;ll enter inside the client container and try to curl Nginx.&lt;/p&gt;
&lt;p&gt;All we need to do to deploy an application is to create a deployment descriptor and submit it to the platform using the CLI.&lt;/p&gt;
&lt;h3 id=&#34;deployment-descriptors&#34;&gt;Deployment descriptors&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1)&lt;/strong&gt; Let&amp;rsquo;s create the Nginx deployment descriptor. Create a file named &lt;code&gt;nginx.yaml&lt;/code&gt; and insert the following.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;api_version: v0.1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;app_name: Nginx
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;app_ns: default
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;service_name: server
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;service_ns: default
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;image: docker.io/library/nginx:latest
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;image_runtime: docker
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;RR_ip: 10.30.30.30
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;port: 80:80
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cmd: []
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;requirements:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    cpu: 1 # cores
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    memory: 200  # in MB
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;2)&lt;/strong&gt; Let&amp;rsquo;s create a client container using the curl image. Create a file named &lt;code&gt;client.yaml&lt;/code&gt; and insert the following.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;api_version: v0.1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;app_name: Client
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;app_ns: default
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;service_name: client
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;service_ns: default
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;image: docker.io/curlimages/curl:7.82.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;image_runtime: docker
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;commands: [&amp;#34;sh&amp;#34;, &amp;#34;-c&amp;#34;, &amp;#34;tail -f /dev/null&amp;#34;]
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;requirements:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    cpu: 1 # cores
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    memory: 100  # in MB
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;A detailed description of these fields can be found in the &lt;strong&gt;Deployment descriptors&lt;/strong&gt; section of the Wiki.&lt;/p&gt;
&lt;h3 id=&#34;deployment-cli&#34;&gt;Deployment CLI&lt;/h3&gt;
&lt;p&gt;On the root orchestrator&amp;rsquo;s node use the following commands to deploy the Nginx container and then the Client container.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -F file=@&amp;#39;nginx.yaml&amp;#39; http://localhost:10000/api/deploy -v
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -F file=@&amp;#39;client.yaml&amp;#39; http://localhost:10000/api/deploy -v
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Check the status of the deployment:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl localhost:10000/api/jobs | json_pp
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;If both services show the status &lt;strong&gt;ACTIVE&lt;/strong&gt; then everything went fine. Otherwise, there might be a configuration issue or a bug. Please debug it with &lt;code&gt;docker logs system_manager -f --tail=100&lt;/code&gt; on the root orchestrator and with &lt;code&gt;docker logs cluster_manager -f --tail=100&lt;/code&gt; on the cluster orchestrator and open an issue.&lt;/p&gt;
&lt;p&gt;If both services are ACTIVE is time to test the communication.&lt;/p&gt;
&lt;p&gt;Move into the worker node hosting the client and use the following command to log into the container.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo ctr -n edge.io task exec --exec-id term1 Client.default.client.default /bin/sh
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Once we are inside our client, we can curl the Nginx server and check if everything works.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl 10.30.30.30
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Note that this address is the one we specified in the Nginx&amp;rsquo;s deployment descriptor.&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
