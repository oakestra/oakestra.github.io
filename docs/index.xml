<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title> – Wiki</title>
    <link>https://oakestra.io/docs/</link>
    <description>Recent content in Wiki on </description>
    <generator>Hugo -- gohugo.io</generator>
    
	  <atom:link href="https://oakestra.io/docs/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Your First Oakestra Cluster</title>
      <link>https://oakestra.io/docs/getstarted/get-started-cluster/</link>
      <pubDate>Wed, 05 Oct 2022 09:56:27 +0200</pubDate>
      
      <guid>https://oakestra.io/docs/getstarted/get-started-cluster/</guid>
      <description>
        
        
        &lt;p&gt;&lt;img src=&#34;https://oakestra.io/wiki-banner-help.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table of content:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#high-level-architecture&#34;&gt;High-level archtecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#create-your-first-oakestra-cluster&#34;&gt;Create your first Oakestra cluster&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;high-level-architecture&#34;&gt;High-level architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/getstarted/highLevelArch.png&#34; alt=&#34;High level architecture picture&#34;&gt;&lt;/p&gt;
&lt;p&gt;Oakestra lets you deploy your workload on devices of any size. From a small RasperryPi to a cloud instance far away on GCP or AWS. The tree structure enables you to create multiple clusters of resources.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;strong&gt;Root Orchestrator&lt;/strong&gt; manages different clusters of resources. The root only sees aggregated cluster resources.&lt;/li&gt;
&lt;li&gt;The &lt;strong&gt;Cluster orchestrator&lt;/strong&gt; manages your worker nodes. This component collects the real-time resources and schedules your workloads to the perfect matching device.&lt;/li&gt;
&lt;li&gt;A &lt;strong&gt;Worker&lt;/strong&gt; is any device where a component called NodeEngine is installed. Each node can support multiple execution environments such as Containers (containerd runtime), MicroVM (containerd runtime), and Unikernels (mirageOS).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disclaimer, currently, only containers are supported. Help is still needed for Unikernels and MicroVMs.&lt;/p&gt;
&lt;h2 id=&#34;create-your-first-oakestra-cluster&#34;&gt;Create your first Oakestra cluster&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s start simple with a single node deployment, where all the components are in the same device. Then, we will separate the components and use multiple devices until we&amp;rsquo;re able to create multiple clusters.&lt;/p&gt;
&lt;h3 id=&#34;requirements&#34;&gt;Requirements:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Linux (Workers only)&lt;/li&gt;
&lt;li&gt;Docker + Docker compose (Orchestrators only)&lt;/li&gt;
&lt;li&gt;Cluster Orchestrator and Root Orchestrator machines must be mutually reachable.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;1-doc-1-device-one-cluster&#34;&gt;1-DOC (1 Device, One Cluster)&lt;/h3&gt;
&lt;p&gt;In this example, we will use a single device to deploy all the components. This is not recommended for production environments, but it is pretty cool for home environments and development.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/getstarted/SingleNodeExample.png&#34; alt=&#34;Deployment example with a single device&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0)&lt;/strong&gt; First, let&amp;rsquo;s export the required environment variables&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Shell&#34; data-lang=&#34;Shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;## Choose a unique name for your cluster&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;CLUSTER_NAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;My_Awesome_Cluster
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;## Come up with a name for the current location&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;CLUSTER_LOCATION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;My_Awesome_Apartment
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;1)&lt;/strong&gt; now clone the repository and move into it using:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Shell&#34; data-lang=&#34;Shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/oakestra/oakestra.git &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; oakestra
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;2)&lt;/strong&gt; Run a local 1-DOC cluster&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Shell&#34; data-lang=&#34;Shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo -E docker-compose -f run-a-cluster/1-DOC.yaml up
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;3)&lt;/strong&gt; download, untar and install the node engine package&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Shell&#34; data-lang=&#34;Shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget -c https://github.com/oakestra/oakestra/releases/download/v0.4.2/NodeEngine_&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;.tar.gz &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; tar -xzf NodeEngine_&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;.tar.gz &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; chmod +x install.sh &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; mv NodeEngine NodeEngine_&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; ./install.sh &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;4)&lt;/strong&gt; (optional) download and unzip and install the network manager; this enables an overlay network across your services&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Shell&#34; data-lang=&#34;Shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget -c https://github.com/oakestra/oakestra-net/releases/download/v0.4.2/NetManager_&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;.tar.gz &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; tar -xzf NetManager_&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;.tar.gz &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; chmod +x install.sh &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; ./install.sh &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;( please replace &amp;lt; arch &amp;gt; with your device architecture: &lt;strong&gt;arm-7&lt;/strong&gt; or &lt;strong&gt;amd64&lt;/strong&gt; )&lt;/p&gt;
&lt;p&gt;4.1) Edit &lt;code&gt;/etc/netmanager/netcfg.json&lt;/code&gt; as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Shell&#34; data-lang=&#34;Shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;NodePublicAddress&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&amp;lt;IP ADDRESS OF THIS DEVICE&amp;gt;&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;NodePublicPort&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&amp;lt;PORT REACHABLE FROM OUTSIDE, use 50103 as default&amp;gt;&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;ClusterUrl&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;localhost&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;ClusterMqttPort&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;10003&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;4.2) start the NetManager on port 6000&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo NetManager -p 6000 &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;5)&lt;/strong&gt; start the NodeEngine. Please only use the &lt;code&gt;-n 6000&lt;/code&gt; parameter if you started the network component in step 4. This parameter, in fact, is used to specify the internal port of the network component, if any.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Shell&#34; data-lang=&#34;Shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo NodeEngine -n &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;6000&lt;/span&gt; -p &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;10100&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;( you can use &lt;code&gt;NodeEngine -h&lt;/code&gt; for further details )&lt;/p&gt;
&lt;h3 id=&#34;m-doc-m-devices-one-cluster&#34;&gt;M-DOC (M Devices, One Cluster)&lt;/h3&gt;
&lt;p&gt;The M-DOC deployment enables you to deploy One cluster with multiple worker nodes. The main difference between this deployment and 1-DOC is that the worker nodes might be external here, and there can be multiple of them.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/getstarted/1ClusterExample.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The deployment of this kind of cluster is similar to 1-DOC. We first need to start the root and cluster orchestrator. Afterward, we can attach the worker nodes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1)&lt;/strong&gt; On the node you wish to use as a cluster and root orchestrator, execute steps &lt;strong&gt;1-DOC.1&lt;/strong&gt; and &lt;strong&gt;1-DOC.2&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2)&lt;/strong&gt; Now, we need to prepare all the worker nodes. On each worker node, execute the following:&lt;/p&gt;
&lt;p&gt;2.1) Downlaod and unpack both the NodeEngine&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Shell&#34; data-lang=&#34;Shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget -c https://github.com/oakestra/oakestra/releases/download/v0.4.2/NodeEngine_&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;.tar.gz &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; tar -xzf NodeEngine_&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;.tar.gz &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; chmod +x install.sh &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; mv NodeEngine NodeEngine_&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; ./install.sh &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;and the NetManager&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Shell&#34; data-lang=&#34;Shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;wget -c https://github.com/oakestra/oakestra-net/releases/download/v0.4.2/NetManager_&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;.tar.gz &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; tar -xzf NetManager_&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;.tar.gz &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; chmod +x install.sh &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; ./install.sh &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;$(&lt;/span&gt;dpkg --print-architecture&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;2.2) Edit &lt;code&gt;/etc/netmanager/netcfg.json&lt;/code&gt; accordingly:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Shell&#34; data-lang=&#34;Shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;NodePublicAddress&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&amp;lt;IP ADDRESS OF THIS DEVICE&amp;gt;&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;NodePublicPort&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&amp;lt;PORT REACHABLE FROM OUTSIDE, internal port is always 50103&amp;gt;&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;ClusterUrl&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&amp;lt;IP ADDRESS OF THE CLSUTER ORCHESTRATOR&amp;gt;&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;ClusterMqttPort&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;10003&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;2.3) Run the NetManager and the NodeEngine components:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Shell&#34; data-lang=&#34;Shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo NetManager -p &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;6000&lt;/span&gt; &lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;&amp;amp;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo NodeEngine -n &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;6000&lt;/span&gt; -p &lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;10100&lt;/span&gt; -a &amp;lt;IP ADDRESS OF THE CLSUTER ORCHESTRATOR&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;mdnc-m-devices-n-clusters&#34;&gt;MDNC (M Devices, N Clusters)&lt;/h3&gt;
&lt;p&gt;This represents the most versatile deployment. You can split your resources into multiple clusters within different locations and with different resources. In this deployment, we need to deploy the Root and the Cluster orchestrator on different nodes. Each independent clsuter orchestrator represents a cluster of resources. The worker nodes attached to each cluster are aggregated and seen as a unique big resource from the point of view of the Root. This deployment isolates the resources from the root perspective and delegates the responsibility to the cluster orchestrator.
&lt;img src=&#34;https://oakestra.io/getstarted/2ClusterExample.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1)&lt;/strong&gt; In this first step, we need to deploy the RootOrchestrator component on a Node. To do this, you need to clone the repository on the desired node, move to the root orchestrator folder, and execute the startup command.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Shell&#34; data-lang=&#34;Shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/edgeIO/edgeio.git &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; edgeio
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo -E docker-compose -f root_orchestrator/docker-compose-&amp;lt;arch&amp;gt;.yml up
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;( please replace &amp;lt; arch &amp;gt; with your device architecture: &lt;strong&gt;arm&lt;/strong&gt; or &lt;strong&gt;amd64&lt;/strong&gt; )&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2)&lt;/strong&gt; For each node that needs to host a cluster orchestrator, you need to:
2.1) Export the ENV variables needed to connect to the cluster orchestrator:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Shell&#34; data-lang=&#34;Shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;SYSTEM_MANAGER_URL&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;IP ADDRESS OF THE NODE HOSTING THE ROOT ORCHESTRATOR&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;CLUSTER_NAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;choose a name &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; your cluster&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;CLUSTER_LOCATION&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;choose a name &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; the cluster&lt;span style=&#34;color:#a40000&#34;&gt;&amp;#39;&lt;/span&gt;s location&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;2.2) Clone the repo and run the cluster orchestrator:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Shell&#34; data-lang=&#34;Shell&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/edgeIO/edgeio.git &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; edgeio
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sudo -E docker-compose -f cluster_orchestrator/docker-compose-&amp;lt;arch&amp;gt;.yml up
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;( please replace &amp;lt; arch &amp;gt; with your device architecture: &lt;strong&gt;arm&lt;/strong&gt; or &lt;strong&gt;amd64&lt;/strong&gt; )&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3)&lt;/strong&gt; Start and configure each worker as described in M-DOC.2&lt;/p&gt;
&lt;h3 id=&#34;hybrids&#34;&gt;Hybrids&lt;/h3&gt;
&lt;p&gt;You should have got the gist now, but if you want, you can build the infrastructure by composing the components like LEGO blocks.
Do you want to give your Cluster Orchestrator computational capabilities for the deployment? Deploy there the NodeEngine+Netmanager components, and you&amp;rsquo;re done. You don&amp;rsquo;t want to use a separate node for the Root Orchestrator? Simply deploy it all together with a cluster orchestrator.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Deploy your first App</title>
      <link>https://oakestra.io/docs/getstarted/get-started-app/</link>
      <pubDate>Wed, 05 Oct 2022 09:56:27 +0200</pubDate>
      
      <guid>https://oakestra.io/docs/getstarted/get-started-app/</guid>
      <description>
        
        
        &lt;p&gt;&lt;img src=&#34;https://oakestra.io/wiki-banner-help.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table of content:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#deploy-your-first-applications&#34;&gt;Requirements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deploy-your-first-applications&#34;&gt;Deploy your first applications&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;You have a running Root Orchestrator with at least one Cluster Orchestrator registered.&lt;/li&gt;
&lt;li&gt;You have at least one Worker Node Registered&lt;/li&gt;
&lt;li&gt;(Optional) If you want the microservices to communicate, you need to have the NetManager installed and properly configured.&lt;/li&gt;
&lt;li&gt;You can access the APIs at &lt;code&gt;&amp;lt;root-orch-ip&amp;gt;:10000/api/docs&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deploy-your-first-application&#34;&gt;Deploy your first application&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s try deploying an Nginx server and a client. Then we&amp;rsquo;ll enter inside the client container and try to curl Nginx.&lt;/p&gt;
&lt;p&gt;All we need to do to deploy an application is to create a deployment descriptor and submit it to the platform using the APIs.&lt;/p&gt;
&lt;h3 id=&#34;deployment-descriptor&#34;&gt;Deployment descriptor&lt;/h3&gt;
&lt;p&gt;In order to deploy a container a deployment descriptor must be passed to the deployment command.
The deployment descriptor contains all the information that Oakestra needs in order to achieve a complete
deploy in the system.&lt;/p&gt;
&lt;p&gt;Since version 0.4, Oakestra (previously, EdgeIO) uses the following deployment descriptor format.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;deploy_curl_application.yaml&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;sla_version&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;v2.0&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;customerID&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Admin&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;applications&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;{&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;applicationID&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;application_name&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;clientsrvr&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;application_namespace&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;test&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;application_desc&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;Simple demo with curl client and Nginx server&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;microservices&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;{&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;microserviceID&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;microservice_name&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;curl&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;microservice_namespace&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;test&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;virtualization&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;container&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;cmd&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;sh&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;-c&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;tail -f /dev/null&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;],&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;memory&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;100&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;vcpus&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;vgpus&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;vtpus&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;bandwidth_in&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;bandwidth_out&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;storage&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;code&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;docker.io/curlimages/curl:7.82.0&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;state&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;port&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;9080&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;added_files&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[]&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;}&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;{&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;microserviceID&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;microservice_name&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;nginx&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;microservice_namespace&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;test&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;virtualization&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;container&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;cmd&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[],&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;memory&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;100&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;vcpus&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;vgpus&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;vtpus&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;bandwidth_in&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;bandwidth_out&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;storage&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;code&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;docker.io/library/nginx:latest&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;state&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;port&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;6080:80/tcp&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;addresses&amp;#34;: &lt;/span&gt;{&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;rr_ip&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;10.30.30.30&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;}&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;,&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;&amp;#34;added_files&amp;#34;: &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;[]&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;}&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;}&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;]&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;}&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This deployment descriptor example generates one application named &lt;em&gt;clientserver&lt;/em&gt; with the &lt;code&gt;test&lt;/code&gt; namespace and two microservices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nginx server with test namespace, namely &lt;code&gt;clientserver.test.nginx.test&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;curl client with test namespace, namely &lt;code&gt;clientserver.test.curl.test&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is a detailed description of the deployment descriptor fields currently implemented:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sla_version: the current version is v0.2&lt;/li&gt;
&lt;li&gt;customerID: id of the user, default is Admin
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;application list, in a single deployment descriptor is possible to define multiple applications, each containing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fully qualified app name: A fully qualified name in Oakestra is composed of
&lt;ul&gt;
&lt;li&gt;application_name: unique name representing the application (max 10 char, no symbols)&lt;/li&gt;
&lt;li&gt;application_namespace: namespace of the app, used to reference different deployment of the same application. Examples of namespace name can be &lt;code&gt;default&lt;/code&gt; or &lt;code&gt;production&lt;/code&gt; or &lt;code&gt;test&lt;/code&gt; (max 10 char, no symbols)&lt;/li&gt;
&lt;li&gt;applicationID: leave it empty for new deployments, this is needed only to edit an existing deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;application_desc: Short description of the application&lt;/li&gt;
&lt;li&gt;microservice list, a list of the microservices composing the application. For each microservice the user can specify:
&lt;ul&gt;
&lt;li&gt;microserviceID: leave it empty for new deployments, this is needed only to edit an existing deployment.&lt;/li&gt;
&lt;li&gt;Fully qualified service name:
&lt;ul&gt;
&lt;li&gt;microservice_name: name of the service (max 10 char, no symbols)&lt;/li&gt;
&lt;li&gt;microservice_namespace: namespace of the service, used to reference different deployment of the same service. Examples of namespace name can be &lt;code&gt;default&lt;/code&gt; or &lt;code&gt;production&lt;/code&gt; or &lt;code&gt;test&lt;/code&gt; (max 10 char, no symbols)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;virtualization: currently the only uspported virtualization is &lt;code&gt;container&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;cmd: list of the commands to be executed inside the container at startup&lt;/li&gt;
&lt;li&gt;vcpu,vgpu,memory: minimum cpu/gpu vcores and memory amount needed to run the container&lt;/li&gt;
&lt;li&gt;vtpus: currently not implemented&lt;/li&gt;
&lt;li&gt;storage: minimum storage size required (currently the scheduler does not take this value into account)&lt;/li&gt;
&lt;li&gt;bandwidth_in/out: minimum required bandwith on the worker node. (currently the scheduler does not take this value into account)&lt;/li&gt;
&lt;li&gt;port: port mapping for the container in the syntax hostport_1:containerport_1[/protocol];hostport_2:containerport_2[/protocol] (default protocol is tcp)&lt;/li&gt;
&lt;li&gt;addresses: allows to specify a custom ip address to be used to balance the traffic across all the service instances.
&lt;ul&gt;
&lt;li&gt;rr_ip: [optional filed] This field allows you to setup a custom Round Robin network address to reference all the instances belonging to this service. This address is going to be permanently bounded to the service. The address MUST be in the form &lt;code&gt;10.30.x.y&lt;/code&gt; and must not collide with any other Instance Address or Service IP in the system, otherwise an error will be returned. If you don&amp;rsquo;t specify a RR_ip and you don&amp;rsquo;t set this field, a new address will be generated by the system.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;constraints: array of constraints regarding the service.
&lt;ul&gt;
&lt;li&gt;type: constraint type
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;direct&lt;/code&gt;: Send a deployment to a specific cluster and a specific list of eligible nodes. You can specify &lt;code&gt;&amp;quot;node&amp;quot;:&amp;quot;node1;node2;...;noden&amp;quot;&lt;/code&gt; a list of node&amp;rsquo;s hostnames. These are the only eligible worker nodes.  &lt;code&gt;&amp;quot;cluster&amp;quot;:&amp;quot;cluster_name&amp;quot;&lt;/code&gt; The name of the cluster where this service must be scheduled. E.g.:&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;#34;constraints&amp;#34;:[
            {
              &amp;#34;type&amp;#34;:&amp;#34;direct&amp;#34;,
              &amp;#34;node&amp;#34;:&amp;#34;xavier1&amp;#34;,
              &amp;#34;cluster&amp;#34;:&amp;#34;gpu&amp;#34;
            }
          ]
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;login-to-the-apis&#34;&gt;Login to the APIs&lt;/h3&gt;
&lt;p&gt;After running a cluster you can use the debug OpenAPI page to interact with the apis and use the infrastructure&lt;/p&gt;
&lt;p&gt;connect to &lt;code&gt;&amp;lt;root_orch_ip&amp;gt;:10000/api/docs&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Authenticate using the following procedure:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;locate the login method and use the try-out button
&lt;img src=&#34;https://oakestra.io/getstarted/login-try.png&#34; alt=&#34;try-login&#34;&gt;&lt;/li&gt;
&lt;li&gt;Use the default Admin credentials to login
&lt;img src=&#34;https://oakestra.io/getstarted/login-execute.png&#34; alt=&#34;execute-login&#34;&gt;&lt;/li&gt;
&lt;li&gt;Copy the result login token
&lt;img src=&#34;https://oakestra.io/getstarted/login-token-copy.png&#34; alt=&#34;token-login&#34;&gt;&lt;/li&gt;
&lt;li&gt;Go to the top of the page and authenticate with this token
&lt;img src=&#34;https://oakestra.io/getstarted/authorize.png&#34; alt=&#34;auth-login&#34;&gt;
&lt;img src=&#34;https://oakestra.io/getstarted/authorize-2.png&#34; alt=&#34;auth2-login&#34;&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;register-an-application-and-the-services&#34;&gt;Register an application and the services&lt;/h3&gt;
&lt;p&gt;After you authenticate with the login function, you can try out to deploy the first application.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Upload the deployment description to the system. You can try using the deployment descriptor above.
&lt;img src=&#34;https://oakestra.io/getstarted/post-app.png&#34; alt=&#34;post app&#34;&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The response contains the Application id and the id for all the application&amp;rsquo;s services. Now the application and the services are registered to the platform. It&amp;rsquo;s time to deploy the service instances!&lt;/p&gt;
&lt;p&gt;You can always remove or create a new service for the application using the /api/services endpoints&lt;/p&gt;
&lt;h3 id=&#34;deploy-an-instance-of-a-registered-service&#34;&gt;Deploy an instance of a registered service&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Trigger a deployment of a service&amp;rsquo;s instance using &lt;code&gt;POST /api/service/{serviceid}/instance&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;each call to this endpoint generates a new instance of the service&lt;/p&gt;
&lt;h3 id=&#34;monitor-the-service-status&#34;&gt;Monitor the service status&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;With &lt;code&gt;GET /api/aplications/&amp;lt;userid&amp;gt;&lt;/code&gt; (or simply /api/aplications/ if you&amp;rsquo;re admin) you can check the list of the deployed application.&lt;/li&gt;
&lt;li&gt;With &lt;code&gt;GET /api/services/&amp;lt;appid&amp;gt;&lt;/code&gt; you can check the services attached to an application&lt;/li&gt;
&lt;li&gt;With &lt;code&gt;GET /api/service/&amp;lt;serviceid&amp;gt;&lt;/code&gt; you can check the status for all the instances of &lt;serviceid&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;undeploy&#34;&gt;Undeploy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Use &lt;code&gt;DELETE /api/service/&amp;lt;serviceid&amp;gt;&lt;/code&gt; to delete all the instances of a service&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;DELETE /api/service/&amp;lt;serviceid&amp;gt;/instance/&amp;lt;instance number&amp;gt;&lt;/code&gt; to delete a specific instance of a service&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;DELETE /api/application/&amp;lt;appid&amp;gt;&lt;/code&gt; to delete all together an application with all the services and instances&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;check-if-the-deployment-succeded&#34;&gt;Check if the deployment succeded&lt;/h3&gt;
&lt;p&gt;Familiarize yourself with the API and discover for each one of the service the status and the public address.&lt;/p&gt;
&lt;p&gt;If both services show the status &lt;strong&gt;ACTIVE&lt;/strong&gt; then everything went fine. Otherwise, there might be a configuration issue or a bug. Please debug it with &lt;code&gt;docker logs system_manager -f --tail=1000&lt;/code&gt; on the root orchestrator, with &lt;code&gt;docker logs cluster_manager -f --tail=1000&lt;/code&gt; on the cluster orchestrator and checking the logs of the NetManager and NodeEngine. Then please open an issue.&lt;/p&gt;
&lt;p&gt;If both services are ACTIVE, it is time to test the communication.&lt;/p&gt;
&lt;p&gt;Try to reach the nginx server you just deployed reaching: http://&amp;lt;deployment_machine_ip&amp;gt;:6080 If you see the Nginx landing page the deployment succeeded! Hurray! 🎉&lt;/p&gt;
&lt;p&gt;If you want to try the semantic addressing, move into the worker node hosting the client and use the following command to log into the container.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo ctr -n edge.io task exec --exec-id term1 Client.default.client.default /bin/sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once we are inside our client, we can curl the Nginx server and check if everything works.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;curl 10.30.30.30
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note that this address is the one we specified in the Nginx&amp;rsquo;s deployment descriptor.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Semantic addressing</title>
      <link>https://oakestra.io/docs/networking/semantic-addressing/</link>
      <pubDate>Wed, 01 Mar 2023 12:56:27 +0200</pubDate>
      
      <guid>https://oakestra.io/docs/networking/semantic-addressing/</guid>
      <description>
        
        
        &lt;p&gt;The default networking component of Oakestra envisions IP communication based on a semantic balancing policy expressed by some special IP addresses.&lt;/p&gt;
&lt;h2 id=&#34;what-do-we-mean-by-semantic-addressing&#34;&gt;What do we mean by semantic addressing?&lt;/h2&gt;
&lt;p&gt;In Oakestra, the addresses belonging to the subnetwork 10.30.0.0/16 are called &lt;strong&gt;Service IPs&lt;/strong&gt;. Similar to a cluster IP in Kubernetes, these addresses reference all the instances(replicas) of a microservice with a single address. This address does not change when scaling up the instances or when migrating them.
Anyway, unlike the Kubernetes cluster IP, when deploying a service in Oakestra, the platform provides as many ServiceIP addresses as the number of balancing policies supported (and active) within the platform.
On top of that, we have a special subset of the Service IPs called &lt;strong&gt;Instance IPs&lt;/strong&gt;. An Instance IP balances the traffic only to a specific service instance within the system.
Let&amp;rsquo;s take a look at the following example.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/network/NetExample.png&#34; alt=&#34;NetExample&#34;&gt;&lt;/p&gt;
&lt;p&gt;A developer can communicate with any instance of Service B either with &lt;strong&gt;Round Robin&lt;/strong&gt; balancing policy or the &lt;strong&gt;Closest&lt;/strong&gt; balancing policy. The former balances the traffic evenly between all the instances, and the latter finds the geographically closer instance.&lt;/p&gt;
&lt;p&gt;Service A performs the first request &lt;img src=&#34;https://oakestra.io/network/NetArchExample_evenlope_1.png&#34; alt= &#34;envelope_1&#34; width=&#34;30&#34;&gt; using the ServiceIP &lt;font style=&#34;color:red&#34;&gt;10.30.0.1&lt;/font&gt; representing the closest instance balancing policy.
The network components&amp;rsquo; proxy converts the address to the Namespace IP of Service B Instance 1, which looks like it is the geographically closer service. The message will be, therefore &lt;strong&gt;transparently&lt;/strong&gt; delivered to the closest instance of Service B. Note that the Namespace IP is the real address of the instance, the one provisioned at deployment time, unique and dynamic. An application developer never sees or uses this address, as it depends on the subnetwork of the specific machine where the service is deployed. Find out more about the Namespace IP by reading the implementation details.&lt;/p&gt;
&lt;p&gt;Then, Service A performs a second request &lt;img src=&#34;https://oakestra.io/network/NetArchExample_evenlope_2.png&#34; alt= &#34;envelope_1&#34; width=&#34;30&#34;&gt; using the ServiceIP &lt;font style=&#34;color:blue&#34;&gt;10.30.0.2&lt;/font&gt; representing the Round Robin balancing policy. The network components&amp;rsquo; proxy converts the address to the Namespace IP of Service B Instance 3, which is randomly chosen among all the available instances.&lt;/p&gt;
&lt;p&gt;When Service A performs a third request &lt;img src=&#34;https://oakestra.io/network/NetArchExample_evenlope_3.png&#34; alt= &#34;envelope_3&#34; width=&#34;30&#34;&gt; using again the ServiceIP &lt;font style=&#34;color:blue&#34;&gt;10.30.0.2&lt;/font&gt; representing the Round Robin balancing policy, this time, the network components&amp;rsquo; proxy randomly chooses Service B Instance 2.&lt;/p&gt;
&lt;p&gt;The last request &lt;img src=&#34;https://oakestra.io/network/NetArchExample_evenlope_4.png&#34; alt= &#34;envelope_4&#34; width=&#34;30&#34;&gt; from Service A to Service B uses the Instance IP representing instance 3. The proxy component then automatically chooses Service B Instance 3&lt;/p&gt;
&lt;h4 id=&#34;why-do-we-need-instance-ips&#34;&gt;Why do we need Instance IPs?&lt;/h4&gt;
&lt;p&gt;Mainly for 2 reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Instance IPs represent a service&amp;rsquo;s instance uniquely within the platform. Even when the instance migrates toward new devices, the Instance IP always represents the instance and not the machine where the instance is deployed. The Instance IP is the foundation that enables an overlay network that abstracts services from machines.&lt;/li&gt;
&lt;li&gt;When forwarding the packet, the proxy uses the sender&amp;rsquo;s Instance IP in the &lt;code&gt;from&lt;/code&gt; header field of the packet. This way, any response or connection-oriented protocol can transparently work, and we guarantee the original sender receives the response.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;why-service-ips-why-do-we-need-multiple-balancing-policies&#34;&gt;Why Service IPs? Why do we need multiple balancing policies?&lt;/h4&gt;
&lt;p&gt;At the Edge, Oakestra&amp;rsquo;s net component enables flexibility in the way developers can balance the traffic without the requirement of adapting the code. Just by using a Service IP instead of a regular IP, a developer can achieve balancing by using any protocol based on UDP or TCP and can also customize the balancing behavior of each request accordingly to their need. Edge computing brings resources closer to the users, so one might need to forward some traffic with very low latency using Closest balancing policy, or one might just want to evenly balance another endpoint with Round Robin policy.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Contribution Guide</title>
      <link>https://oakestra.io/docs/contribute/contribution-guide/</link>
      <pubDate>Mon, 17 Oct 2022 10:39:27 +0200</pubDate>
      
      <guid>https://oakestra.io/docs/contribute/contribution-guide/</guid>
      <description>
        
        
        &lt;h1 id=&#34;oakestra-contribution-guide&#34;&gt;Oakestra Contribution guide&lt;/h1&gt;
&lt;p&gt;Oakestra&amp;rsquo;s codebase is open-source on GitHub and open to &lt;strong&gt;external&lt;/strong&gt; contributors as well. The purpose of this guide is to help the developer contribute in such a way that both people directly involved in Okaestra and people outside the research group can follow what happens within the project.&lt;/p&gt;
&lt;h2 id=&#34;issues&#34;&gt;Issues&lt;/h2&gt;
&lt;p&gt;Each contribution starts from an issue on the corresponding repository. E.g., Are you willing to update the front end? Open an issue on the dashboard repository.&lt;/p&gt;
&lt;p&gt;The issue can be of two kinds: &lt;strong&gt;Proposal&lt;/strong&gt; or &lt;strong&gt;Bug&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Template for &lt;strong&gt;Proposal&lt;/strong&gt; issues:&lt;/p&gt;
&lt;blockquote&gt;
&lt;h1 id=&#34;short&#34;&gt;Short&lt;/h1&gt;
&lt;p&gt;Short description of what you&amp;rsquo;re proposing. Max 2 lines. Highlight if this is something new or maybe you&amp;rsquo;re willing to change some specific behavior.&lt;/p&gt;
&lt;h1 id=&#34;proposal&#34;&gt;Proposal&lt;/h1&gt;
&lt;p&gt;Description of the modification you&amp;rsquo;re proposing. You can have references, links, and images. Please be very specific here. External contributors must be able to understand the context and the goal of the proposal.&lt;/p&gt;
&lt;h1 id=&#34;ratio&#34;&gt;Ratio&lt;/h1&gt;
&lt;p&gt;Short description of why this is important&lt;/p&gt;
&lt;h1 id=&#34;impact&#34;&gt;Impact&lt;/h1&gt;
&lt;p&gt;Describe the components that potentially need to be touched. E.g., Root service manager, Cluster scheduler, etc.&lt;/p&gt;
&lt;h1 id=&#34;development-time&#34;&gt;Development time&lt;/h1&gt;
&lt;p&gt;The expected time required to complete the development of this proposal&lt;/p&gt;
&lt;h1 id=&#34;status&#34;&gt;Status&lt;/h1&gt;
&lt;p&gt;Describe the current status of this proposal. E.g., looking for feedback, searching for a solution, development, and testing. Try to be concise but descriptive.&lt;/p&gt;
&lt;h1 id=&#34;checklist&#34;&gt;Checklist&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Discussed&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Documented&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Implemented&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Tested&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Template for &lt;strong&gt;Bug&lt;/strong&gt; issues:&lt;/p&gt;
&lt;blockquote&gt;
&lt;h1 id=&#34;short-1&#34;&gt;Short&lt;/h1&gt;
&lt;p&gt;Short description of the bug you noticed.&lt;/p&gt;
&lt;h1 id=&#34;proposal-1&#34;&gt;Proposal&lt;/h1&gt;
&lt;p&gt;Deeper description of the bug.&lt;/p&gt;
&lt;h1 id=&#34;solution&#34;&gt;Solution&lt;/h1&gt;
&lt;p&gt;Eventually, propose a solution.&lt;/p&gt;
&lt;h1 id=&#34;status-1&#34;&gt;Status&lt;/h1&gt;
&lt;p&gt;Describe the current status of this proposal. E.g., looking for feedback, searching for a solution, development, testing. Try to be concise but descriptive&lt;/p&gt;
&lt;h1 id=&#34;checklist-1&#34;&gt;Checklist&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Discussed&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Solved&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Tested&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;issue-names&#34;&gt;Issue names&lt;/h2&gt;
&lt;p&gt;Try to be concise and informative. Here some good ✅ and bad ❌ examples to give you an idea.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Scheduling  ❌&lt;/li&gt;
&lt;li&gt;Integration of LDA to Cluster Scheduler ✅&lt;/li&gt;
&lt;li&gt;Frontend edit ❌&lt;/li&gt;
&lt;li&gt;Frontend cluster management panel ✅&lt;/li&gt;
&lt;li&gt;I think we need to replace the login token with a new JWT token ❌&lt;/li&gt;
&lt;li&gt;JWT API authentication ✅&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;contribution-steps&#34;&gt;Contribution steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Open an Issue or Pick one&lt;/li&gt;
&lt;li&gt;Assign it to yourself, or ask for it.&lt;/li&gt;
&lt;li&gt;Fork the develop branch and detach a branch named after the issue&lt;/li&gt;
&lt;li&gt;When the issue is solved, tested and discussed in your fork, propose a PR towards the develop branch. Don&amp;rsquo;t forget to link the PR to the issue using the proper &lt;a href=&#34;https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue&#34;&gt;keywords&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;If necessary, update the &lt;a href=&#34;https://github.com/oakestra/documentation&#34;&gt;documentation&lt;/a&gt; as well using the same procedure&lt;/li&gt;
&lt;li&gt;Make sure that the PR passes all the automated tests.&lt;/li&gt;
&lt;li&gt;Add the maintainers as Reviewers.&lt;/li&gt;
&lt;li&gt;Don&amp;rsquo;t disappear, try to stay active in the discussion section until required.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;multi-repo-contributions&#34;&gt;Multi-repo contributions&lt;/h2&gt;
&lt;p&gt;The codebase is split into multiple repositories. Sometimes a single contribution might need to span across some of them in parallel. This is where things get tricky.&lt;/p&gt;
&lt;p&gt;Contributions spanning multiple repositories are difficult to track and require careful management.&lt;/p&gt;
&lt;p&gt;Please open multiple issues, one for each repository, and cross-link them. Each issue discusses only the modification required on that specific repository but links to the issues embedding the work required elsewhere.&lt;/p&gt;
&lt;p&gt;As a general rule, is better to perform the merges in parallel.
Make sure to open the pull requests together and cross-link the other pull requests between them.&lt;/p&gt;
&lt;h2 id=&#34;your-work-into-issues&#34;&gt;Your work into Issues&lt;/h2&gt;
&lt;p&gt;Try to find out the single tasks of your workflow and open up the corresponding issues accordingly.
Breaking down the work into issues makes it easier to merge and test the features.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;N.b.&lt;/strong&gt; Always assign the issue to yourself and maybe indicate if this is part of a specific milestone, thesis, or guided research.&lt;/p&gt;
&lt;h2 id=&#34;discuss-with-the-community&#34;&gt;Discuss with the community&lt;/h2&gt;
&lt;p&gt;With the growth in the interest for Oakestra, many people are onboarding. By collaborating on this project, you have the chance to ask for their ideas as well.&lt;/p&gt;
&lt;p&gt;Try to write the issues in a clear way so that anyone might be able to fit in and contribute.
Then keep an eye on the issue&amp;rsquo;s comment section and add the label &amp;ldquo;help needed&amp;rdquo; if required.&lt;/p&gt;
&lt;h2 id=&#34;versioning&#34;&gt;Versioning&lt;/h2&gt;
&lt;p&gt;The project version is written in the file &lt;code&gt;version.txt&lt;/code&gt;
Make sure to update this file accordingly.&lt;/p&gt;
&lt;p&gt;N.b. The versions are amanged only by this file. NEVER CREATE A VERSION TAG MANUALLY.&lt;/p&gt;
&lt;h2 id=&#34;release-images&#34;&gt;Release images&lt;/h2&gt;
&lt;p&gt;An accepted pull-request towards main creates a release TAG corresponding to the version in &lt;code&gt;version.txt&lt;/code&gt;.
The release images will be created automatically by the git workflows.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If a release tag exist already, will not be replaced. You need to increase the version number!&lt;/li&gt;
&lt;li&gt;If you get an artifact creation error, most likely the release was not yet created on github. Please create a new release for the new tag and re-run the failed jobs.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;alpha-images&#34;&gt;Alpha images&lt;/h2&gt;
&lt;p&gt;An accepted pull-request towards develop creates an alpha TAG corresponding to the version in &lt;code&gt;version.txt&lt;/code&gt; with the &lt;code&gt;alpha-&lt;/code&gt; prefix. If the tag exists already, it will be updated.
The alpha images will be created automatically by the git workflows.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you get an artifact creation error, most likely the release was not yet created on github. Please create a new alpha-release for the new tag and re-run the failed jobs.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>About: Contacts</title>
      <link>https://oakestra.io/about/contacts/</link>
      <pubDate>Wed, 10 Aug 2022 11:28:03 +0200</pubDate>
      
      <guid>https://oakestra.io/about/contacts/</guid>
      <description>
        
        
        &lt;h2 id=&#34;our-discussion-group&#34;&gt;Our discussion group&lt;/h2&gt;
&lt;p&gt;Join our github discussion group &lt;a href=&#34;https://github.com/oakestra/oakestra/discussions&#34;&gt;HERE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Feel free to post questions and ideas or ask about any problem you have.&lt;/p&gt;
&lt;p&gt;In our team section, you can also find a list of people you can contact directly by email, socials, and, why not, carrier pigeons as well.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>About: Team</title>
      <link>https://oakestra.io/about/team/</link>
      <pubDate>Wed, 10 Aug 2022 11:27:56 +0200</pubDate>
      
      <guid>https://oakestra.io/about/team/</guid>
      <description>
        
        
        &lt;ul&gt;
&lt;li&gt;Giovanni Bartolomeo
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;mailto:giovanni.bartolomeo@tum.de&#34;&gt;giovanni.bartolomeo@tum.de&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mehdi Yosofie&lt;/li&gt;
&lt;li&gt;Oliver Haluszczynsci&lt;/li&gt;
&lt;li&gt;Simon Bäurle&lt;/li&gt;
&lt;li&gt;Maximilian Eder&lt;/li&gt;
&lt;li&gt;Patrick Sabanic&lt;/li&gt;
&lt;li&gt;Sonia Klärmann&lt;/li&gt;
&lt;li&gt;Ralf Baun&lt;/li&gt;
&lt;li&gt;Daniel Mair&lt;/li&gt;
&lt;li&gt;Maria Vienalas&lt;/li&gt;
&lt;li&gt;Dr. Nitinder Mohan
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;mailto:mohan@in.tum.de&#34;&gt;mohan@in.tum.de&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Prof. Jörg Ott&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Contributor Covenant Code of Conduct</title>
      <link>https://oakestra.io/docs/contribute/coc/</link>
      <pubDate>Tue, 09 Aug 2022 15:56:27 +0200</pubDate>
      
      <guid>https://oakestra.io/docs/contribute/coc/</guid>
      <description>
        
        
        &lt;h1 id=&#34;contributor-covenant-code-of-conduct&#34;&gt;Contributor Covenant Code of Conduct&lt;/h1&gt;
&lt;h2 id=&#34;our-pledge&#34;&gt;Our Pledge&lt;/h2&gt;
&lt;p&gt;In the interest of fostering an open and welcoming environment, we as
contributors and maintainers pledge to make participation in our project and
our community a harassment-free experience for everyone, regardless of age, body
size, disability, ethnicity, sex characteristics, gender identity and expression,
level of experience, education, socio-economic status, nationality, personal
appearance, race, religion, or sexual identity and orientation.&lt;/p&gt;
&lt;h2 id=&#34;our-standards&#34;&gt;Our Standards&lt;/h2&gt;
&lt;p&gt;Examples of behavior that contributes to creating a positive environment
include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using welcoming and inclusive language&lt;/li&gt;
&lt;li&gt;Being respectful of differing viewpoints and experiences&lt;/li&gt;
&lt;li&gt;Gracefully accepting constructive criticism&lt;/li&gt;
&lt;li&gt;Focusing on what is best for the community&lt;/li&gt;
&lt;li&gt;Showing empathy towards other community members&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Examples of unacceptable behavior by participants include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The use of sexualized language or imagery and unwelcome sexual attention or
advances&lt;/li&gt;
&lt;li&gt;Trolling, insulting/derogatory comments, and personal or political attacks&lt;/li&gt;
&lt;li&gt;Public or private harassment&lt;/li&gt;
&lt;li&gt;Publishing others&amp;rsquo; private information, such as a physical or electronic
address, without explicit permission&lt;/li&gt;
&lt;li&gt;Other conduct which could reasonably be considered inappropriate in a
professional setting&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;our-responsibilities&#34;&gt;Our Responsibilities&lt;/h2&gt;
&lt;p&gt;Project maintainers are responsible for clarifying the standards of acceptable
behavior and are expected to take appropriate and fair corrective action in
response to any instances of unacceptable behavior.&lt;/p&gt;
&lt;p&gt;Project maintainers have the right and responsibility to remove, edit, or
reject comments, commits, code, wiki edits, issues, and other contributions
that are not aligned to this Code of Conduct, or to ban temporarily or
permanently any contributor for other behaviors that they deem inappropriate,
threatening, offensive, or harmful.&lt;/p&gt;
&lt;h2 id=&#34;scope&#34;&gt;Scope&lt;/h2&gt;
&lt;p&gt;This Code of Conduct applies within all project spaces, and it also applies when
an individual is representing the project or its community in public spaces.
Examples of representing a project or community include using an official
project e-mail address, posting via an official social media account, or acting
as an appointed representative at an online or offline event. Representation of
a project may be further defined and clarified by project maintainers.&lt;/p&gt;
&lt;h2 id=&#34;enforcement&#34;&gt;Enforcement&lt;/h2&gt;
&lt;p&gt;Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported by contacting the project team at [INSERT EMAIL ADDRESS]. All
complaints will be reviewed and investigated and will result in a response that
is deemed necessary and appropriate to the circumstances. The project team is
obligated to maintain confidentiality with regard to the reporter of an incident.
Further details of specific enforcement policies may be posted separately.&lt;/p&gt;
&lt;p&gt;Project maintainers who do not follow or enforce the Code of Conduct in good
faith may face temporary or permanent repercussions as determined by other
members of the project&amp;rsquo;s leadership.&lt;/p&gt;
&lt;h2 id=&#34;attribution&#34;&gt;Attribution&lt;/h2&gt;
&lt;p&gt;This Code of Conduct is adapted from the &lt;a href=&#34;https://www.contributor-covenant.org&#34;&gt;Contributor Covenant&lt;/a&gt;, version 1.4,
available at &lt;a href=&#34;https://www.contributor-covenant.org/version/1/4/code-of-conduct.html&#34;&gt;https://www.contributor-covenant.org/version/1/4/code-of-conduct.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For answers to common questions about this code of conduct, see
&lt;a href=&#34;https://www.contributor-covenant.org/faq&#34;&gt;https://www.contributor-covenant.org/faq&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: High level architecture</title>
      <link>https://oakestra.io/docs/oakestra/architecture/</link>
      <pubDate>Tue, 09 Aug 2022 15:56:27 +0200</pubDate>
      
      <guid>https://oakestra.io/docs/oakestra/architecture/</guid>
      <description>
        
        
        &lt;p&gt;&lt;img src=&#34;https://oakestra.io/oakestra/wiki-banner-help.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;table-of-content&#34;&gt;Table of content&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#root-orchestrator&#34;&gt;Root Orchestrator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cluster-orchestrator&#34;&gt;Cluster Orchestrator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#worker-node&#34;&gt;Worker Node&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;oakestra-detailed-architecture&#34;&gt;Oakestra Detailed Architecture&lt;/h1&gt;
&lt;p&gt;As shown in our &lt;a href=&#34;get-started.md&#34;&gt;Get Started&lt;/a&gt; guide, Oakestra uses 3-4 building blocks to operate.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Root Orchestrator&lt;/li&gt;
&lt;li&gt;Cluster Orchestrator&lt;/li&gt;
&lt;li&gt;Node Engine&lt;/li&gt;
&lt;li&gt;NetManager (optional, detailed in the networking section of the Wiki)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This section of the wiki is intended for people willing to contribute to the project and it is meant to describe some internal architectural details.&lt;/p&gt;
&lt;h2 id=&#34;root-orchestrator&#34;&gt;Root Orchestrator&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/oakestra/RootArch.png&#34; alt=&#34;root architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;The Root Orchestrator is a centralized control plane that is aware of the participating clusters.&lt;/p&gt;
&lt;p&gt;This picture describes the containers that compose the Root Orchestrator. As you may have seen we use docker-compose to bring up the orchestrators. This is because each block of this picture is &lt;em&gt;currently&lt;/em&gt; a separated container.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The System Manager is the point of contact for users, developers, or operators to use the system as an application deployment platform. It exposes APIs to receive deployment commands from users (application management) and APIs to handle slave Cluster Orchestrators. Cluster Orchestrators send their information
regularly, and the System Manager is aware of those clusters.&lt;/li&gt;
&lt;li&gt;The scheduler calculates a placement for a given application within the available clusters.&lt;/li&gt;
&lt;li&gt;Mongo is the interface we use to access the database. We store aggregated information about the participating clusters. We differentiate between static metadata and dynamic data. The former covers the IP address, port number, name, and location of each cluster. The latter can be data that is
changing regularly, such as the number of worker nodes per cluster, total amount of CPU cores and memory size, total amount of disk space, GPU capabilities, etc.&lt;/li&gt;
&lt;li&gt;The Root Network Components are detailed in the Oakestra-Net Wiki.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;system-manager-apis&#34;&gt;System Manager APIs&lt;/h3&gt;
&lt;p&gt;At startup, the System Manager exposes the public APIs at &amp;lt;root_orch_ip&amp;gt;:10000
Thr API documentation is available at &lt;code&gt;&amp;lt;root_orch_ip&amp;gt;:10000/api/docs&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;consideration-regarding-failure-and-scalability&#34;&gt;Consideration regarding failure and scalability:&lt;/h3&gt;
&lt;p&gt;The main problem of a centralized control plane is that it can act as a single point of failure. By design without a Root Orchestrator, the clusters are able to satisfy the SLA for the deployed applications internally, the only affected functionalities are the deployment of new services and the intra-cluster migrations. To avoid failure and increase resiliency, an idea is to make the component able to scale by introducing a load balancer in front of the replicated components. However, this feature is not implemented yet.&lt;/p&gt;
&lt;h2 id=&#34;cluster-orchestrator&#34;&gt;Cluster Orchestrator&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/oakestra/clusterArch.png&#34; alt=&#34;cluster architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;The Cluster orchestrator is a twin of the root but with the following differences:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The cluster orchestrator&amp;rsquo;s scope is the end worker node devices.&lt;/li&gt;
&lt;li&gt;A cluster orchestrator performs aggregation. It aggregates the worker node resources and does not expose the cluster composition directly to the root.&lt;/li&gt;
&lt;li&gt;The cluster uses MQTT for communication with the worker nodes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;mqtt-topics&#34;&gt;MQTT Topics&lt;/h3&gt;
&lt;p&gt;The topics used to interact with the worker nodes are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;nodes/&lt;node-id&gt;/information$&amp;rdquo;: topic where each worker periodically posts its resources usage&lt;/li&gt;
&lt;li&gt;&amp;ldquo;nodes/&lt;node-id&gt;/job$&amp;rdquo;: used to perform deployments on a worker node and receive back the feedback&lt;/li&gt;
&lt;li&gt;&amp;ldquo;nodes/&lt;node-id&gt;/jobs/resources$&amp;rdquo;: used to post the resource usage and status of the running instances in a worker node&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;schedulers-algorithms&#34;&gt;Schedulers Algorithms&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/oakestra/scheduling-celery-worker.png&#34; alt=&#34;scheduler&#34;&gt;&lt;/p&gt;
&lt;p&gt;The schedulers, at each level, receive Job Placement tasks and return a placement decision.
At the root level, the placement decision is a Cluster. At the cluster level, the placement decision is a worker node.&lt;/p&gt;
&lt;p&gt;A job placement task is a Job structure composed of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Service
&lt;ul&gt;
&lt;li&gt;Instances&lt;/li&gt;
&lt;li&gt;Requirements&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Placement currently uses the default Best Fist algorithm. You can find more details in the scheduling section of the wiki.&lt;/p&gt;
&lt;h2 id=&#34;worker-node&#34;&gt;Worker Node&lt;/h2&gt;
&lt;p&gt;A machine, in order to be qualified as Worker Node, must contain a Node Engine and optionally a Net Manager. The former enables the deployment of applications accordingly to the runtimes installed. The latter plugs the networking components to enable communication across the applications deployed.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/oakestra/nodeEngineArch.png&#34; alt=&#34;NodeEngine&#34;&gt;&lt;/p&gt;
&lt;p&gt;The Node Engine is a single binary implemented using Go Lang and is composed of the following modules:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MQTT: This is the interface between the worker and the Cluster. The deployment commands, node status updates, and jobs updates use this component.&lt;/li&gt;
&lt;li&gt;Models: This contains the models that describe the node and the jobs.
&lt;ul&gt;
&lt;li&gt;Node: describes the resources of the node that are transmitted to the cluster. This is decomposed into dynamic resources and static. The status of static resources is transmitted only at startup. Dynamic resource statuses such as cpu/memory usage are updated regularly.&lt;/li&gt;
&lt;li&gt;Service: describe the fields of the services that are managed by this implementation of the worker node, as well as the real-time service usage statistics that must be monitored.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Jobs: Background jobs that monitor the status of the Worker node itself and the applications deployed.&lt;/li&gt;
&lt;li&gt;Runtimes: Contains the glue with the supported system runtimes. Right now, the runtime dispatcher only supports containerd and, therefore, &amp;ldquo;containers&amp;rdquo; is the only runtime available. Any new runtime integration is implemented here. We&amp;rsquo;re currently working on Unikernels integration.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: IPv4 Service IP implementation details</title>
      <link>https://oakestra.io/docs/networking/service-ip-overlay-implementation/</link>
      <pubDate>Tue, 09 Aug 2022 15:56:27 +0200</pubDate>
      
      <guid>https://oakestra.io/docs/networking/service-ip-overlay-implementation/</guid>
      <description>
        
        
        &lt;p&gt;In this wiki page, we&amp;rsquo;ll go through the details of the IPv4 implementation of the Service IPs in Oakestra.&lt;/p&gt;
&lt;p&gt;The building blocks are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Network Overlays&lt;/li&gt;
&lt;li&gt;Proxy Translation&lt;/li&gt;
&lt;li&gt;Interest registration&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;network-overlays&#34;&gt;Network Overlays&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/network/Overlay-layers.png&#34; alt=&#34;Overlay Example&#34;&gt;&lt;/p&gt;
&lt;p&gt;The abstraction required to enable service-to-service communication spans 3 different layers.&lt;/p&gt;
&lt;h4 id=&#34;physical-layer&#34;&gt;Physical layer&lt;/h4&gt;
&lt;p&gt;At the very bottom of the hierarchy, we have the physical layer, where we address machines rather than microservices or containers.
In this space, an IP address is an address that can be used to uniquely identify a machine and reach it. In Oakestra, we keep track of this layer, pairing each service with a &lt;strong&gt;Node IP&lt;/strong&gt; and &lt;strong&gt;Port&lt;/strong&gt;. The pair IP:port enables us to reach multiple devices sharing the same IP address (NAT). Each worker node exposes the network stack required to enable the upper layers of the overlay at the assigned port.&lt;/p&gt;
&lt;h4 id=&#34;virtual-layer&#34;&gt;Virtual layer&lt;/h4&gt;
&lt;p&gt;Each physical machine is provisioned with a virtual subnetwork. The subnetwork is assigned by the root orchestrator. When instantiating a container, the system provides a so-called &lt;strong&gt;Namespace IP&lt;/strong&gt;, which is an IPv4 address provisioned from the virtual subnetwork of the node. This address is used to route the traffic within the platform to the running containers. The current implementation uses a default fixed netmask of 26 bits for the node subnetwork from the private 10.18.0.0/16 network, allowing over 1024 devices, each supporting 64 containers, for a maximum of 65536 containers. Support for more devices and bigger subnetworks can be achieved by changing the default subnetwork to, i.e., 10.0.0.0/8 or even further transitioning to virtual IPv6 networking.&lt;/p&gt;
&lt;h4 id=&#34;service-layer&#34;&gt;Service layer&lt;/h4&gt;
&lt;p&gt;This is the layer where we abstract from the virtualization technology in use to a Service.
The service layer does not take into consideration the physical positioning of services, the number of instances of each service, the subnetworks, or the routing. This layer provides abstractions that allow the developers to forget about the underlying implementation and just address the service required for the business logic of the application.
This abstraction is enabled by the &lt;strong&gt;Service IPs&lt;/strong&gt;. These are a set of IPv4 addresses that identify services and all their instances and that can be used to transparently pick the right instance and establish a connection. A Service IP expresses an inherent balancing policy, and, for each service, we have as many Service IPs as the implemented system balancing policies (Look at the Semantic Addressing page of this wiki for more details).&lt;/p&gt;
&lt;p&gt;A subset of the Service IPs are the &lt;strong&gt;Instance IPs&lt;/strong&gt;. They balance the traffic always to a specific instance of a service. Therefore, when deploying a service, the system will provision the following addresses:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1 Load Balanced Service IP for each balancing policy implemented in the system&lt;/li&gt;
&lt;li&gt;1 Instance IP for each new instance of the service that has been deployed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The latest version of Oakestra (v0.4.201), only implements Round Robin Service IPs.&lt;/p&gt;
&lt;p&gt;One might ask, &lt;strong&gt;what&amp;rsquo;s the difference between an Instance IP and a Namespace IP?&lt;/strong&gt; They operate on 2 different abstraction layers. The Namespace IP depends on the virtualized subnetwork of a worker node and changes when migrating an application from one node to another. It cannot be provisioned beforehand and must not be used by developers. The Instance IP is part of the Service layer abstraction. Therefore it identifies an instance regardless of migration operations, scales up, scales down, and can be provisioned even before the deployment of a service instance.&lt;/p&gt;
&lt;h2 id=&#34;proxy-translation&#34;&gt;Proxy Translation&lt;/h2&gt;
&lt;p&gt;The Service layer networking is achieved thanks to a worker-level tun-proxy transparently instantiated as part of the Oakestra network component. The following picture is an example of what happens in a worker node based on the IPv4 implementation of the NetManager component.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/network/Overlay-example.png&#34; alt=&#34;Overlay Example&#34;&gt;&lt;/p&gt;
&lt;p&gt;In this example, we have two worker nodes, namely Node 1 and Node 2, each containing two containers. The containers are instantiated and managed by the NodeEngine (See High-Level Architecture wiki), while the Net Manager, creates a network namespace for each container (the cloud surrounding the container), enabling the Virtual Layer abstraction.&lt;/p&gt;
&lt;p&gt;The Service Layer abstraction is realized hierarchically with a mechanism of route Interest Registration and Proxying Translation. This section details the proxy Translation, hence the mechanism that allows transparent conversion of Service IPs into Namespace IPs, therefore transparent Virtual Layer - Service Layer conversion.&lt;/p&gt;
&lt;p&gt;Following the example mentioned above, suppose we deployed services X1 and X3 using the following deployment descriptor.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;{
  &amp;#34;sla_version&amp;#34; : &amp;#34;v2.0&amp;#34;,
  &amp;#34;customerID&amp;#34; : &amp;#34;Admin&amp;#34;,
  &amp;#34;applications&amp;#34; : [
    {
      &amp;#34;applicationID&amp;#34; : &amp;#34;&amp;#34;,
      &amp;#34;application_name&amp;#34; : &amp;#34;X&amp;#34;,
      &amp;#34;application_namespace&amp;#34; : &amp;#34;default&amp;#34;,
      &amp;#34;application_desc&amp;#34; : &amp;#34;X application&amp;#34;,
      &amp;#34;microservices&amp;#34; : [
        {
          &amp;#34;microserviceID&amp;#34;: &amp;#34;&amp;#34;,
          &amp;#34;microservice_name&amp;#34;: &amp;#34;X1&amp;#34;,
          &amp;#34;microservice_namespace&amp;#34;: &amp;#34;default&amp;#34;,
          &amp;#34;virtualization&amp;#34;: &amp;#34;container&amp;#34;,
          &amp;#34;code&amp;#34;: &amp;#34;docker.io/X/X1&amp;#34;,
          &amp;#34;addresses&amp;#34;: {
            &amp;#34;rr_ip&amp;#34;: &amp;#34;10.30.0.1&amp;#34;
          },
        },
        {
          &amp;#34;microserviceID&amp;#34;: &amp;#34;&amp;#34;,
          &amp;#34;microservice_name&amp;#34;: &amp;#34;X3&amp;#34;,
          &amp;#34;microservice_namespace&amp;#34;: &amp;#34;default&amp;#34;,
          &amp;#34;virtualization&amp;#34;: &amp;#34;container&amp;#34;,
          &amp;#34;code&amp;#34;: &amp;#34;docker.io/X/X3&amp;#34;,
          &amp;#34;addresses&amp;#34;: {
            &amp;#34;rr_ip&amp;#34;: &amp;#34;10.30.1.30&amp;#34;
          	},
        }
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Therefore we register into the platform two services, &lt;code&gt;X.default.X1.default&lt;/code&gt; and &lt;code&gt;X.default.X3.default&lt;/code&gt;. At deployment time, we request 2 instances of X1 (&lt;code&gt;X.default.X1.default.0&lt;/code&gt; and &lt;code&gt;X.default.X1.default.1&lt;/code&gt;) and one instance of X3 (&lt;code&gt;X.default.X3.default.0&lt;/code&gt;). The scheduling decision places the instances as shown in the picture.
From the deployment descriptor, we asked the platform to provision the Service IP &lt;code&gt;10.30.1.30&lt;/code&gt; to X3 with Round Robin policy. Therefore, X1 will use this address to perform load-balanced requests toward X3.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;font style=&#34;color:black;background:red&#34;&gt;&lt;b&gt;   1   &lt;/b&gt;&lt;/font&gt; &lt;font style=&#34;color:black;background:orange&#34;&gt;&lt;b&gt; http://10.30.1.30:30443/api/hello &lt;/b&gt;&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;X1 performs a GET request using the Service IP &lt;code&gt;10.30.1.30&lt;/code&gt;. The default getaway for the &lt;code&gt;10.0.0.0/8&lt;/code&gt; subnetwork is the ProxyTUN component of the Net Manager. The request will be directed there.
From an L4 perspective, the packet will look somewhat like this:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;from ip: 10.19.1.3
to ip: 10.30.1.30
from port: 34278
to port: 30443
payload: ....
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;from ip&lt;/code&gt;, is the Virtual Layer IP, the &lt;strong&gt;Namespace IP&lt;/strong&gt; of the container. This Namespace IP is assigned to the VETH device used to connect the container namespace to the virtual bridge in the system namespace.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;font style=&#34;color:black;background:red&#34;&gt;&lt;b&gt;   2   &lt;/b&gt;&lt;/font&gt; &lt;font style=&#34;color:black;background:orange&#34;&gt;&lt;b&gt; Cache Miss &lt;/b&gt;&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;When receiving the request packet, the proxy does not yet have an active conversion entry in its cache. This results in a cache miss. With a cache miss, the proxy TUN fetches the information required for the conversion to the Environment Manager. This component keeps track of the services deployed internally in the worker node, as well as the relevant services deployed on other worker nodes.&lt;/p&gt;
&lt;p&gt;This is an example of the Conversion Table maintained by the Environment Manager at this moment.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/network/Overlay-example-table-before.png&#34; alt=&#34;Overlay Example&#34;&gt;&lt;/p&gt;
&lt;p&gt;The entries of the table keep the cross-layer information of each service, including the physical layer address and port, the virtual layer address, and all the service layer addresses. As the number of records is limited, the table only keeps track of the services currently deployed in this machine. No interest in external services has been recorded so far.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;font style=&#34;color:black;background:red&#34;&gt;&lt;b&gt;   3   &lt;/b&gt;&lt;/font&gt; &lt;font style=&#34;color:black;background:orange&#34;&gt;&lt;b&gt; Table query &lt;/b&gt;&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;When the address &lt;code&gt;10.30.1.30&lt;/code&gt; must be converted using the Conversion Table, this will result in a &lt;strong&gt;table miss&lt;/strong&gt;. The Environment Manager is then forced to ask the cluster orchestration for an entry that enables the conversion of this address.
This operation is called &lt;strong&gt;table query&lt;/strong&gt; and serves a double purpose:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hierarchical lookup to fetch the required information.&lt;/li&gt;
&lt;li&gt;If the information exists, an interest in that information is registered. Therefore any update, such as a service migration or service scaling, results in an update for that table entry.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is one of the building blocks of the proposed abstraction, and it is detailed in the Interest Registration section.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;font style=&#34;color:black;background:red&#34;&gt;&lt;b&gt;   4   &lt;/b&gt;&lt;/font&gt; &lt;font style=&#34;color:black;background:orange&#34;&gt;&lt;b&gt; Update &lt;/b&gt;&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;Upon completion of the table query, the internal Conversion table is updated as follows.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/network/Overlay-example-table-after.png&#34; alt=&#34;Overlay Example&#34;&gt;&lt;/p&gt;
&lt;p&gt;The cluster resolved the Service IP &lt;code&gt;10.30.1.30&lt;/code&gt; into a table entry describing only &lt;code&gt;X.default.X3.default.0&lt;/code&gt; (apparently, no other instances are in the system yet).&lt;/p&gt;
&lt;p&gt;The Environment Manager can now answer the proxy with the &lt;em&gt;virtual layer&lt;/em&gt; and &lt;em&gt;physical layer&lt;/em&gt; addresses resolving the previous cache miss and the balancing policy metadata associated with the address. In this case the response will look like this:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;policy: Round Robin
instances: [
	{
		NS IP: 10.21.0.1
		Node IP: 131.1.21.5
		Node port: 55301
		Cluster: 1
		...
		... 
	}
]
&lt;/code&gt;&lt;/pre&gt;&lt;hr&gt;
&lt;p&gt;&lt;font style=&#34;color:black;background:red&#34;&gt;&lt;b&gt;   5   &lt;/b&gt;&lt;/font&gt; &lt;font style=&#34;color:black;background:orange&#34;&gt;&lt;b&gt; Service IP conversion: from: 10.30.1.30 to 10.21.0.1 &lt;/b&gt;&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;Given the resolution details, the proxy, using the balancing policy information, picks an instance from the instance list and adds an entry to the conversion list.&lt;/p&gt;
&lt;p&gt;In this example, the entry will look like this:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;                FROM              TO
                __________________________________
matching rule:  10.19.1.3:34278 - 10.30.1.30:30443
convert to:     10.30.0.2:34278 - 10.21.0.1:30443
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Notice how the proxy also replaces the &lt;code&gt;from&lt;/code&gt; address with the &lt;strong&gt;Instance IP&lt;/strong&gt; of X1.&lt;/p&gt;
&lt;p&gt;In abstract terms, the proxy is converting a the incoming packet from the form of&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;{
	from:&amp;lt;Sender Virtual Layer Address&amp;gt; 
	to:&amp;lt;Receiver Service Layer Address&amp;gt;
} 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;to&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;{
	from:&amp;lt;Sender Service Layer Address&amp;gt;
	to:&amp;lt;Receiver Virtual Layer Address&amp;gt; 
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The conversion just shown is the key to enabling transparent Service Layer abstraction.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;font style=&#34;color:black;background:red&#34;&gt;&lt;b&gt;   6   &lt;/b&gt;&lt;/font&gt; &lt;font style=&#34;color:black;background:orange&#34;&gt;&lt;b&gt; UDP to 131.1.21.5:55301 &lt;/b&gt;&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;In this step, we see how the ProxyTUN uses the &lt;strong&gt;Physical layer&lt;/strong&gt; information to create a tunnel between Node 1 and Node 2 and forward the packet to the destination machine&amp;rsquo;s Net Manager.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;font style=&#34;color:black;background:red&#34;&gt;&lt;b&gt;   7   &lt;/b&gt;&lt;/font&gt; &lt;font style=&#34;color:black;background:orange&#34;&gt;&lt;b&gt; http://10.21.0.1:30443/api/hello &lt;/b&gt;&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;The Net Manager does not need to translate the incoming packet as the recipient IP is a &lt;strong&gt;Virtual layer&lt;/strong&gt; known address. Notice how a response from X3 to X1 follows the same steps shown in this example.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;interest-registration&#34;&gt;Interest Registration&lt;/h2&gt;
&lt;p&gt;Here we show a sequence diagram of how a table query and an interest registration work in the worker-cluster-root hierarchy.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/network/Overlay-example-seq.png&#34; alt=&#34;Overlay Example&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The environment manager keeps the &amp;lsquo;interests subscriptions&amp;rsquo; for 10 seconds. If the route is not used for more than 10 seconds, the interest is removed, and the table entry is cleared.&lt;/li&gt;
&lt;li&gt;A cluster maintains an interest as long as at least one worker node is interested in that route.&lt;/li&gt;
&lt;li&gt;A worker node is ALWAYS subscribed to interests regarding the instances deployed internally.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Orchestration</title>
      <link>https://oakestra.io/docs/oakestra/orchestrators/</link>
      <pubDate>Tue, 09 Aug 2022 15:56:27 +0200</pubDate>
      
      <guid>https://oakestra.io/docs/oakestra/orchestrators/</guid>
      <description>
        
        
        &lt;p&gt;#APIs&lt;/p&gt;
&lt;p&gt;Root Orchestrator APIs &lt;a href=&#34;https://app.swaggerhub.com/apis-docs/giobarty/oakestra-root_api/v1#/&#34;&gt;OpenApi Spec&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Task Scheduling</title>
      <link>https://oakestra.io/docs/oakestra/scheduling/</link>
      <pubDate>Tue, 09 Aug 2022 15:56:27 +0200</pubDate>
      
      <guid>https://oakestra.io/docs/oakestra/scheduling/</guid>
      <description>
        
        
        &lt;h2 id=&#34;how-does-the-scheduling-work-in-oakestra&#34;&gt;How does the scheduling work in Oakestra?&lt;/h2&gt;
&lt;p&gt;Oakestra&amp;rsquo;s architecture is composed of two tiers. Resources are divided into clusters. A cluster is seen as the aggregation of all its resources. A job is first scheduled to a cluster, and then the cluster scheduler decides the target worker.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/oakestra/cluster-worker-selection.png&#34; alt=&#34;scheduling algo&#34;&gt;&lt;/p&gt;
&lt;p&gt;The scheduling component is as simple as a Celery worker. The scheduler receives a job description and gives back an allocation target. We differentiate between the Root scheduler and Cluster scheduler. The Root scheduler finds a suitable cluster (step 1), and the Cluster scheduler finds a suitable worker node (step 2).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/oakestra/scheduling-celery-worker.png&#34; alt=&#34;scheduling algo&#34;&gt;&lt;/p&gt;
&lt;p&gt;This scheduling algorithm does not ensure an absolute optimal deployment but consistently reduces the search space.&lt;/p&gt;
&lt;h2 id=&#34;scheduling-algorithm&#34;&gt;Scheduling Algorithm&lt;/h2&gt;
&lt;p&gt;At each layer, the scheduling decision consists of the creation of a &lt;code&gt;candidate_list&lt;/code&gt; of clusters (or workers), the exclusion of unsuitable candidates, and then the selection of the &amp;ldquo;best&amp;rdquo; candidate accordingly to a scheduling algorithm.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://oakestra.io/oakestra/scheduling-algo.png&#34; alt=&#34;scheduling algo&#34;&gt;&lt;/p&gt;
&lt;p&gt;The scheduling algorithms are implemented in the &lt;code&gt;calculation.py&lt;/code&gt; component of each respective scheduler.&lt;/p&gt;
&lt;p&gt;The current released version only implements a &lt;strong&gt;best fit&lt;/strong&gt; and &lt;strong&gt;first fit&lt;/strong&gt; calculation strategies. However, on its way to the release, we have our new LDP algorithm (check it out on our &lt;a href=&#34;https://arxiv.org/pdf/2207.01577.pdf&#34;&gt;whitepaper&lt;/a&gt;).&lt;/p&gt;
&lt;h2 id=&#34;job-constraints&#34;&gt;Job Constraints&lt;/h2&gt;
&lt;p&gt;The Job deployment descriptor allows a developer to specify constraints of 4 types: node &lt;strong&gt;resources&lt;/strong&gt;, &lt;strong&gt;network&lt;/strong&gt; capabilities, &lt;strong&gt;geographical&lt;/strong&gt; positioning, and &lt;strong&gt;direct&lt;/strong&gt; mapping.&lt;/p&gt;
&lt;h3 id=&#34;resources&#34;&gt;Resources&lt;/h3&gt;
&lt;p&gt;The job resource requirements cause the immediate exclusion of a candidate from the candidate list. These resources represent the bare minimum required by the job to operate properly. Here there is a table of the supported resources and the state of development:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Resource type&lt;/th&gt;
&lt;th&gt;Status&lt;/th&gt;
&lt;th&gt;Comments&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Virtualization&lt;/td&gt;
&lt;td&gt;🟢&lt;/td&gt;
&lt;td&gt;Fully functional containers support. Unikernel support is under development.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CPU&lt;/td&gt;
&lt;td&gt;🟢&lt;/td&gt;
&lt;td&gt;Only number of CPU cores&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Memory&lt;/td&gt;
&lt;td&gt;🟢&lt;/td&gt;
&lt;td&gt;Memory requirements in MB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Storage&lt;/td&gt;
&lt;td&gt;🟠&lt;/td&gt;
&lt;td&gt;It is possible to specify it, but it is not &lt;strong&gt;yet&lt;/strong&gt; taken into account by the scheduler&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GPU&lt;/td&gt;
&lt;td&gt;🟠&lt;/td&gt;
&lt;td&gt;Possibility of specifying the GPU cores. But not yet the available GPU drivers. Right now, the support is only for CUDA.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TPU&lt;/td&gt;
&lt;td&gt;🔴&lt;/td&gt;
&lt;td&gt;Not yet under development&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Architecture&lt;/td&gt;
&lt;td&gt;🔴&lt;/td&gt;
&lt;td&gt;Not yet possible to filter out the architecture. With containers, it is possible to use the multi-platform build. This flag is coming out together with the Unikernel support.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;network--geo-constraints&#34;&gt;Network &amp;amp; Geo constraints&lt;/h3&gt;
&lt;p&gt;The networking requirements selection and geographic constraints support are coming out in our next release &lt;strong&gt;v0.5&lt;/strong&gt; and are part of the LDP algorithm update. Stay tuned.&lt;/p&gt;
&lt;h3 id=&#34;direct-mapping-positioning&#34;&gt;Direct mapping positioning&lt;/h3&gt;
&lt;p&gt;It is possible to specify a &lt;strong&gt;direct mapping&lt;/strong&gt; constraint. Therefore, in the deployment description, a developer can specify a list of target clusters and nodes. The scheduling algorithm operates only on the active clusters (or nodes) among the given list.&lt;/p&gt;
&lt;p&gt;This direct mapping approach is currently based on &lt;code&gt;cluster names&lt;/code&gt; and &lt;code&gt;worker hostnames&lt;/code&gt;. We are anyway considering adding a label-based positioning where it is possible to tag resources with custom-defined labels. Stay tuned for more.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
